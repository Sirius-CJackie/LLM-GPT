{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d9452e2-ec72-4f13-83e5-4df70ed2aa26",
   "metadata": {},
   "source": [
    "## 注意力机制\n",
    "    1.simplified self-attention\n",
    "    2.self-attention\n",
    "    3.causal attention\n",
    "    4.multi-head attention\n",
    "传统的注意力机制只是强调输入序列和输出序列之间的关系，但是自注意机制是强调同一输入序列中不同单词之间的关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b9e770d-a5c3-4b74-9dcd-38a17a5a22f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "query = inputs[1]\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query)\n",
    "print(attn_scores_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4a13ef-686c-407a-87da-12f8df88c15c",
   "metadata": {},
   "source": [
    "通过点基的形式计算两个单词之间相似度，理论上点基越大代表向量之间有更高的相似度和对齐度。在计算得到注意力点基的张量之后，需要进行归一化，使注意力权重之和为1，有助于解释和保持LLM训练的稳定性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd7604cd-21c4-4dcc-be52-535bf52b437e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum of scores: tensor(6.5617)\n",
      "Sum: tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
    "print(\"Attention weights:\", attn_weights_2_tmp)\n",
    "print(\"Sum of scores:\",attn_scores_2.sum())\n",
    "print(\"Sum:\", attn_weights_2_tmp.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cae0072e-b0c3-469c-87ef-cb5f6d123145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#使用softmax进行归一化处理\n",
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
    "print(\"Attention weights:\", attn_weights_2_naive)\n",
    "print(\"Sum:\", attn_weights_2_naive.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf6776d-917f-4d13-9086-a5a2e514b00d",
   "metadata": {},
   "source": [
    "#建议平时使用torch提供的softmax函数，因为softmax在处理较大或较小的数值时会遇到数值不稳定情况但是torch中softmax函数是经过优化处理的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f81f2f0-6efd-4359-8cbe-87b0d7b3e765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2 = torch.softmax(attn_scores_2,dim=0)\n",
    "print(\"Attention weights:\", attn_weights_2)\n",
    "print(\"Sum:\", attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f20521ea-1213-4bdb-8047-25fd42511dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i]*x_i\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5ef7a1-3345-4376-8286-ccf967e94bcf",
   "metadata": {},
   "source": [
    "要想完整表示所有单词的上下文关系需要将所有的单词计算出所有context vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e5e1476-006d-4cda-8a1e-87dd4cf4d48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = torch.empty(6,6)\n",
    "attn_scores = inputs @ inputs.T\n",
    "print(attn_scores)\n",
    "#dim=-1,意味softmax将会沿着最后一个维度进行归一化计算\n",
    "attn_weights = torch.softmax(attn_scores, dim=-1) \n",
    "all_context_vecs = attn_weights @ inputs\n",
    "print(all_context_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc942f73-06c3-4874-ae42-08673f64244e",
   "metadata": {},
   "source": [
    "# 我们之前设计的自我注意力机制不能用于训练，只能作为案例来解释该机制的原理。所以接下来我们需要引入一个小概念就是引入三个可以用于后期训练的权重矩阵Wq、Wk、Wv来计算注意力得分矩阵。而不是之前直接通过点积两个嵌入向量来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff96bbfc-2b9f-4ed5-9658-afee5d4c50d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n",
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n",
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n",
      "tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "#定义这三个矩阵的维度将三维降维\n",
    "d_in = inputs.shape[1]                                            \n",
    "d_out = 2 \n",
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad = False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad = False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad = False)\n",
    "#分别计算出查询单词的query值，key和value矩阵\n",
    "query_2 = inputs[1] @ W_query\n",
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)\n",
    "attn_scores_2 = query_2 @ keys.T\n",
    "print(attn_scores_2)\n",
    "#对注意力得分进行归一化但是我们通过将注意力得分除以keys嵌入维度的平方根来进行缩放\n",
    "dims = keys.shape[-1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / dims**0.5, dim=-1)\n",
    "print(attn_weights_2)\n",
    "context_vec_2 = attn_weights_2 @ values\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f3a9d-2992-45d1-b2ae-80ce36383c0a",
   "metadata": {},
   "source": [
    "将注意力缩放的目的是因为我们知道softmax对输入值的差异非常敏感，如果输入的维度过大的时候，点积会产生非常大概率值的结果接近于1，而点积值小的结果会接近于0.表现为step function阶跃函数，所以在之后的反向传播中梯度的更新会非常慢，所以我们需要对注意力进行一个适当的缩放，便于后期的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9766f9bd-970a-4309-9ed5-bf7e2957f3f5",
   "metadata": {},
   "source": [
    "## 为什么使用Q、K和V向量？\n",
    "在注意力机制的上下文中，“键”（key）、“查询”（query）和“值”（value）这些术语来源于信息检索和数据库领域，在这些领域中也使用类似的概念来存储、搜索和检索信息\n",
    "\n",
    "查询（query）类似于数据库中的搜索查询。它代表模型当前关注或试图理解的项（如句子中的某个词或 token）。通过查询，模型可以探查输入序列中的其他部分，以确定对它们应关注的程度。\n",
    "\n",
    "键（key）类似于数据库中用于索引和查找的键。在注意力机制中，输入序列的每个元素（例如句子中的每个单词）都对应一个关联的‘键’。这些‘键’用于与‘查询’进行匹配。\n",
    "\n",
    "值（value）类似于数据库中的键值对中的“值”。它表示输入项的实际内容或表示。当模型确定哪些键（即输入中的哪些部分）与查询（当前的关注项）最相关时，就会检索出对应的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8e826c8-4a81-4523-a088-e1fa3adc6fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将自注意机制进行封装\n",
    "import torch.nn as nn\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        attn_scores = queries @ keys.T # omega\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0ba7827-6a12-4701-9a7f-3be4bf6c54a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n",
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in,d_out)\n",
    "context_vec_3 = sa_v1.forward(inputs)\n",
    "print(sa_v1(inputs))\n",
    "print(context_vec_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3799966b-869a-4f53-9373-514d4df98476",
   "metadata": {},
   "source": [
    "使用 nn.Linear 替代手动实现的 nn.Parameter(torch.rand(...)) 的一个显著优势在于，nn.Linear 具有优化的权重初始化方案，从而有助于实现更稳定和更高效的模型训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2665081-1f83-4918-b1b9-b793101ba7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b14af9b-bca5-4da5-be5a-448202e45107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5085, 0.3508],\n",
      "        [0.5084, 0.3508],\n",
      "        [0.5084, 0.3506],\n",
      "        [0.5074, 0.3471],\n",
      "        [0.5076, 0.3446],\n",
      "        [0.5077, 0.3493]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363c9800-92e1-4ef4-98b6-3b72a451b05a",
   "metadata": {},
   "source": [
    "练习 3.1：比较SelfAttention_v1和 SelfAttention_v2\n",
    "\n",
    "请注意，SelfAttention_v2 中的 nn.Linear 层使用了一种不同的权重初始化方式，而 SelfAttention_v1 则使用 nn.Parameter(torch.rand(d_in, d_out)) 进行初始化。这导致两种机制生成的结果有所不同。为了验证 SelfAttention_v1 和 SelfAttention_v2 的其他部分是否相似，我们可以将 SelfAttention_v2 对象中的权重矩阵转移到 SelfAttention_v1 中，从而使两者生成相同的结果。\n",
    "\n",
    "你的任务是将 SelfAttention_v2 实例中的权重正确分配给 SelfAttention_v1 实例。为此，你需要理解两个版本中权重之间的关系。（提示：nn.Linear 存储的是转置形式的权重矩阵。）分配完成后，你应该能观察到两个实例生成相同的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "649ea53f-2b84-44d9-92cb-888bc771ad7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5085, 0.3508],\n",
      "        [0.5084, 0.3508],\n",
      "        [0.5084, 0.3506],\n",
      "        [0.5074, 0.3471],\n",
      "        [0.5076, 0.3446],\n",
      "        [0.5077, 0.3493]], grad_fn=<MmBackward0>)\n",
      "tensor([[0.5085, 0.3508],\n",
      "        [0.5084, 0.3508],\n",
      "        [0.5084, 0.3506],\n",
      "        [0.5074, 0.3471],\n",
      "        [0.5076, 0.3446],\n",
      "        [0.5077, 0.3493]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    sa_v1.W_query.copy_(sa_v2.W_query.weight.T)\n",
    "    sa_v1.W_key.copy_(sa_v2.W_key.weight.T)\n",
    "    sa_v1.W_value.copy_(sa_v2.W_value.weight.T)\n",
    "print(sa_v2(inputs))\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2874d536-9c20-4b01-baee-36abdddf30f9",
   "metadata": {},
   "source": [
    "# Causal Attention Mechanism(Masked Attention)\n",
    "与之前的自注意力机制的区别在于，该机制值关注序列中前一个和当前输入，而不能看到后续的内容。\n",
    "方法一：将上一节中计算出的归一化的注意力权重矩阵，进行对角线掩码，然后再进行归一化即可。利用softmax的特性，虽然遮掩了部分token，这部分遮掩的token参与了之前softmax的计算，但是在掩码后的重新归一化的权重依旧有效的softmax得分，这就是softmax神奇之处。\n",
    "方法二:将注意力得分矩阵进行掩码后，应用softmax进行归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff6580a7-c4a2-4393-b37e-1f68c4d8da4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1362, 0.1730, 0.1736, 0.1713, 0.1792, 0.1666],\n",
      "        [0.1359, 0.1730, 0.1735, 0.1716, 0.1790, 0.1670],\n",
      "        [0.1366, 0.1729, 0.1734, 0.1714, 0.1788, 0.1669],\n",
      "        [0.1493, 0.1701, 0.1704, 0.1697, 0.1732, 0.1674],\n",
      "        [0.1589, 0.1690, 0.1692, 0.1667, 0.1712, 0.1649],\n",
      "        [0.1408, 0.1715, 0.1718, 0.1717, 0.1758, 0.1684]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_scores = sa_v2.W_query(inputs) @ sa_v2.W_key(inputs).T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51e7e502-8782-4799-bb59-6ea50bffbeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[0.1362, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1359, 0.1730, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1366, 0.1729, 0.1734, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1493, 0.1701, 0.1704, 0.1697, 0.0000, 0.0000],\n",
      "        [0.1589, 0.1690, 0.1692, 0.1667, 0.1712, 0.0000],\n",
      "        [0.1408, 0.1715, 0.1718, 0.1717, 0.1758, 0.1684]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#我们可以使用 PyTorch 的 tril 函数来生成一个掩码矩阵\n",
    "column_length = attn_scores.shape[0]\n",
    "row_length = attn_scores.shape[1]\n",
    "mask_simple = torch.tril(torch.ones(column_length,row_length))\n",
    "print(mask_simple)\n",
    "masked_simple = attn_weights * mask_simple\n",
    "print(masked_simple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e1f8acb-10c3-43ce-bfbd-87efd752e502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1362],\n",
      "        [0.3089],\n",
      "        [0.4829],\n",
      "        [0.6595],\n",
      "        [0.8351],\n",
      "        [1.0000]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "#归一化 参数keepdim是设置输出的张量保持原来的维度，默认为False，输出为一维\n",
    "row_sums = masked_simple.sum(dim=1, keepdim=True)\n",
    "print(row_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1567572-6cb5-4ea6-81f0-f5ba29104551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4400, 0.5600, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2830, 0.3580, 0.3590, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2264, 0.2579, 0.2583, 0.2574, 0.0000, 0.0000],\n",
      "        [0.1903, 0.2024, 0.2026, 0.1997, 0.2051, 0.0000],\n",
      "        [0.1408, 0.1715, 0.1718, 0.1717, 0.1758, 0.1684]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_simple_norm = masked_simple / row_sums\n",
    "print(masked_simple_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12ba836f-2bf3-4348-b331-2829c56f7245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[False,  True,  True,  True,  True,  True],\n",
      "        [False, False,  True,  True,  True,  True],\n",
      "        [False, False, False,  True,  True,  True],\n",
      "        [False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False,  True],\n",
      "        [False, False, False, False, False, False]])\n",
      "tensor([[-0.2327,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.2396,  0.1015,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.2323,  0.1004,  0.1045,    -inf,    -inf,    -inf],\n",
      "        [-0.1344,  0.0502,  0.0523,  0.0470,    -inf,    -inf],\n",
      "        [-0.0349,  0.0520,  0.0538,  0.0331,  0.0708,    -inf],\n",
      "        [-0.2142,  0.0650,  0.0679,  0.0668,  0.1004,  0.0395]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4400, 0.5600, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2830, 0.3580, 0.3590, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2264, 0.2579, 0.2583, 0.2574, 0.0000, 0.0000],\n",
      "        [0.1903, 0.2024, 0.2026, 0.1997, 0.2051, 0.0000],\n",
      "        [0.1408, 0.1715, 0.1718, 0.1717, 0.1758, 0.1684]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#diagonal 参数将对角线上的元素设置为 1\n",
    "mask = torch.triu(torch.ones(column_length, row_length), diagonal=1)\n",
    "print(mask)\n",
    "print(mask.bool())\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(masked)\n",
    "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d9b316-01f3-4d4e-951e-c597d8376ddf",
   "metadata": {},
   "source": [
    "# 使用 dropout遮掩额外的注意力权重\n",
    "这是一种在训练过程忽略一些隐藏单元的技术，防止过拟合。但是dropout尽在训练过程中使用，训练后就会禁用。该技术通常应用与两个特定区域：计算注意力的分之后和将注意力权重应用value向量之后，这个dropout是随机的，而且部分dropout会落在已经masked的区域。当对注意力权重矩阵应用 50% 的 dropout 时，矩阵中一半的元素会被随机设置为零。为了补偿有效元素的减少，矩阵中剩余元素的值会被放大 1/0.5 = 2 倍。这个缩放操作至关重要，可以在训练和推理阶段保持注意力机制的整体权重平衡，确保注意力机制在这两个阶段的平均影响保持一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "964ece34-08f5-4ac9-bfc9-fb563abc060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2., 2., 2., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 2., 0.],\n",
      "        [2., 2., 0., 0., 0., 2.],\n",
      "        [2., 0., 0., 0., 0., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5)                                   #A\n",
    "example = torch.ones(6, 6)                                        #B\n",
    "print(dropout(example))\n",
    "#A 我们使用的dropout率为0.5\n",
    "#B 创建一个由1组成的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53a4dec7-a821-405f-8c09-cabd1ddbd785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.7181, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5159, 0.0000, 0.5147, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4047, 0.4052, 0.3993, 0.4101, 0.0000],\n",
      "        [0.2815, 0.3430, 0.0000, 0.0000, 0.3516, 0.3368]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b32bde1-306c-47a3-9daa-0eee40714b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n",
      "tensor([[[0.4300, 0.1500, 0.8900],\n",
      "         [0.5500, 0.8700, 0.6600],\n",
      "         [0.5700, 0.8500, 0.6400],\n",
      "         [0.2200, 0.5800, 0.3300],\n",
      "         [0.7700, 0.2500, 0.1000],\n",
      "         [0.0500, 0.8000, 0.5500]],\n",
      "\n",
      "        [[0.4300, 0.1500, 0.8900],\n",
      "         [0.5500, 0.8700, 0.6600],\n",
      "         [0.5700, 0.8500, 0.6400],\n",
      "         [0.2200, 0.5800, 0.3300],\n",
      "         [0.7700, 0.2500, 0.1000],\n",
      "         [0.0500, 0.8000, 0.5500]]])\n"
     ]
    }
   ],
   "source": [
    "#stack 是用于将一组张量沿新维度堆叠的函数。该操作会在指定的 dim 位置插入一个新的维度\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape) \n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c914e65e-e790-45dd-896c-3407cf8ce2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 3.3 A compact causal attention class\n",
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)                        #A\n",
    "        self.register_buffer(\n",
    "           'mask',\n",
    "           torch.triu(torch.ones(context_length, context_length),\n",
    "           diagonal=1)\n",
    "        )                                                         #B\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape                             #C\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        attn_scores = queries @ keys.transpose(1, 2)              #C\n",
    "        #这里涉及了广播机制\n",
    "        attn_scores.masked_fill_(                                 #D\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "#这里 keys.transpose(1, 2) 是将键矩阵的第 1 和第 2 维度交换，从 (b, num_tokens, d_out) \n",
    "#变成 (b, d_out, num_tokens)，这样就能与查询矩阵进行点积操作。\n",
    "#A 与之前的 SelfAttention_v1 类相比，我们添加了一个 dropout 层\n",
    "#B register_buffer 调用也是新添加的内容（后续内容会提供更多相关信息）\n",
    "#C 我们交换第 1 和第 2 个维度，同时保持批次维度在第1个位置（索引0）\n",
    "#D 在 PyTorch 中，带有下划线后缀的操作会在原有内存空间执行，直接修改变量本身，从而避免不必要的内存拷贝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f863f41-7d54-4a75-babb-10e199f331da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]],\n",
      "\n",
      "        [[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "context_vecs = ca(batch)\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa7c82f-dce7-4202-b9da-4e845a4f7c08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
