{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f3b04f6-50d9-4755-b03e-0cc6e96b07dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ec1158-0a7e-4728-bad9-5246fe10ac57",
   "metadata": {},
   "source": [
    "# LLM tarining function由一下三步组成\n",
    "1.文本生成 text generation\n",
    "2.文本评估 text evaluation \n",
    "3.评估模型 training & validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84964649-c497-4d86-a43f-8bc4a6d5b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#封装归一化层\n",
    "# Listing 4.2 A layer normalization class\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "#esp是一个小常数 防止出现除以0的错误\n",
    "#unbiased 这个参数设置是为了防止样本过少导致归一化过小，\n",
    "#当设置为true时方差为n-1个样本的，而设置为false的时候就为n个样本\n",
    "#LLM的样本数量较大所以不需要设置贝塞尔校正\n",
    "# 激活层 GELU函数 与 RELU相似\n",
    "# Listing 4.3 An implementation of the GELU activation function\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "# FeedForward网络模块 \n",
    "# Listing 4.4 A feed forward neural network module\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "#上面的MultiHeadAttention是将并行的结果进行拼接，而接下来\n",
    "# 的这种是将结果进行乘积也就是将张量结果组合在一起\n",
    "# Listing 3.5 An efficient multi-head attention class\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads                        #A\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)                   #B\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            'mask',\n",
    "             torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)                                      #C\n",
    "        queries = self.W_query(x)                                 #C\n",
    "        values = self.W_value(x)                                  #C\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)       #D\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)   #D\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim) #D\n",
    "\n",
    "        keys = keys.transpose(1, 2)                               #E\n",
    "        queries = queries.transpose(1, 2)                         #E\n",
    "        values = values.transpose(1, 2)                           #E\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)              #F\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]    #G\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)           #H\n",
    "\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)     #I\n",
    "\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)  #J\n",
    "        context_vec = self.out_proj(context_vec)                  #K\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "#A 将投影维度缩小，以匹配期望的输出维度\n",
    "#B 使用线性层组合头部输出\n",
    "#C 张量形状：(b, num_tokens, d_out)\n",
    "#D 我们通过添加 num_heads 维度来隐式地拆分矩阵。然后展开最后一个维度，使其形状从 (b, num_tokens, d_out) 转换为 (b, num_tokens, num_heads, head_dim)\n",
    "#E 将张量的形状从 (b, num_tokens, num_heads, head_dim) 转置为 (b, num_heads, num_tokens, head_dim)\n",
    "#F 对每个注意力头进行点积运算\n",
    "#G 掩码被截断到 token 的数量\n",
    "#H 使用掩码填充注意力分数\n",
    "#I 张量形状：（b, num_tokens, n_heads, head_dim）\n",
    "#J 将多个注意力头的输出结果合并，其中输出维度 self.d_out 等于注意力头数 self.num_heads 与每个头的维度 self.head_dim 的乘积\n",
    "#K 添加一个可选的线性投影层\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "        d_in=cfg[\"emb_dim\"],\n",
    "        d_out=cfg[\"emb_dim\"],\n",
    "        context_length=cfg[\"context_length\"],\n",
    "        num_heads=cfg[\"n_heads\"],\n",
    "        dropout=cfg[\"drop_rate\"],\n",
    "        qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x                                          #A\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "        shortcut = x                                          #B\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut                                       #C\n",
    "        return x\n",
    "\n",
    "\n",
    "#A 注意力模块中的快捷连接\n",
    "#B 前馈网络模块中的快捷链接\n",
    "#C 将原始输入加回到输出中\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))      #A\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    " #A 设备设置将根据输入数据所在的位置选择在 CPU 或 GPU 上训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e167f44-577a-4d8e-9829-510a3a1fa128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 4.8 A function for the GPT model to generate text\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size): #A\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]                           #B\n",
    "        with torch.no_grad():\n",
    "           logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]                                   #C\n",
    "        probas = torch.softmax(logits, dim=-1)                      #D\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)       #E\n",
    "        #其实softmax最大概率值与源向量组最大值的索引是一样实际上softmax是多余的操作\n",
    "        idx = torch.cat((idx, idx_next), dim=1)                     #F\n",
    "\n",
    "    return idx\n",
    "\n",
    "\n",
    "#A idx 是当前上下文中索引的数组，形状为 (batch, n_tokens)\n",
    "#B 若上下文长度超出支持范围，则进行裁剪。例如，若模型仅支持 5 个 token，而上下文长度为 10，仅使用最后 5 个 token 作为上下文\n",
    "#C 仅关注最后一个时间步，将形状从 (batch, n_token, vocab_size) 转换为 (batch, vocab_size)\n",
    "#D probas 的形状为 (batch, vocab_size)\n",
    "#E idx_next 的形状为 (batch, 1)\n",
    "#F 将采样的索引追加到当前序列中，此时 idx 的形状为 (batch, n_tokens+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22efb7ca-1c71-4ffb-880d-e38222e57ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个函数其实很简单就是制作一个训练数据集和标签数据集\n",
    "#标签数据集其实就是训练数据集往后偏移一位的数据集\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):              \n",
    "        #max_length 是每次读取文本的最大长度\n",
    "        #stride 是步长也就是滑动窗口的大小\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)                                #A\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):          #B\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):                                                     #C\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):                                            #D\n",
    "    \treturn self.input_ids[idx], self.target_ids[idx]\n",
    "#A 将整个文本进行分词\n",
    "#B 使用滑动窗口将书籍分块为最大长度的重叠序列。\n",
    "#C 返回数据集的总行数\n",
    "#D 从数据集中返回指定行\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")                       #A\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)      #B\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "      \tbatch_size=batch_size,\n",
    "      \tshuffle=shuffle,\n",
    "      \tdrop_last=drop_last,                                        #C\n",
    "      \tnum_workers=0                                               #D\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a595ff2c-5ff1-448f-acec-feb46d55f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,        #A\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,             #B\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a66ed8-ec7c-4d2a-bfac-5dc9fd7f8ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c220223-4fd7-462c-90de-847bd8e015ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c09b32a3-da4c-42ec-809a-a97303766eb4",
   "metadata": {},
   "source": [
    "## 文本生成函数封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5198d5d-705d-4a7c-a190-024deac02558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "# 我们封装encoding和decoding函数\n",
    "import tiktoken\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c660484-86d0-42cb-a9f1-dc9262e12abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n",
      "Targets batch 2: � like chocolate\n",
      "Outputs batch 2:  pressuring empoweredfaith\n"
     ]
    }
   ],
   "source": [
    "# 文本生成损失计算\n",
    "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
    "                       [40, 1107, 588]])    # \"I really like\"]\n",
    "# Matching these inputs, the `targets` contain the token IDs we aim for the model to produce:\n",
    "targets = torch.tensor([[3626, 6100, 345 ], # [\" effort moves you\",\n",
    "                        [107, 588, 11311]]) # \" really like chocolate\"]\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n",
    "print(f\"Targets batch 2: {token_ids_to_text(targets[1], tokenizer)}\")\n",
    "print(f\"Outputs batch 2: {token_ids_to_text(token_ids[1].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f2cd28-2f11-4a08-9452-7913fc8f97dd",
   "metadata": {},
   "source": [
    "# 模型评估\n",
    "对模型生成的输出进行数值化评估,正确softmax位置上概率越高,模型效果越好\n",
    "也就是将下面输出的概率值尽量接近于1\n",
    "想要最大化softmax值就要使反向传播寻找权重参数的梯度下降,但是反向传播需要一个损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba91402b-3d74-483c-a394-fc3caa4e130b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([3.9108e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8985008-4796-4a9f-a55c-8411c8511e07",
   "metadata": {},
   "source": [
    "# 概率得分的损失计算\n",
    "1.求出logits的proba\n",
    "2.根据target提取对应索引的proba\n",
    "3.取对数\n",
    "4.计算平均值\n",
    "5.平均值取正数\n",
    "# 这个损失函数计算方式类似 cross entropy\n",
    "Loss = -∑ yP（y）\n",
    "我们知道cross entropy主要用于分类任务的loss计算，而分类任务一般y采用one-hot编码，所以Loss = =p（y1）-P（y2）- ... - P(yn),这里Py1..Pyn都是target维度的概率值。\n",
    "所以这个概率得分的损失函数1-5步其实就是cross entropy计算方法的步骤\n",
    "因此，是否有1/n取决于是否在批量训练下对多个样本的交叉熵损失取平均值。如果是在计算整个批次的损失，那么通常会有 1/n 来平均损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5651039-dc1c-4936-be35-1434f8c45b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -10.1492,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d87964e-300d-4370-9f91-ed9820dc2a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.5722)\n",
      "tensor(10.5722)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)\n",
    "neg_avg_log_probas = -1*avg_log_probas\n",
    "print(neg_avg_log_probas)\n",
    "#这种将负值 -10.7940 转化为正值 10.7940 的操作在深度学习中称为交叉熵损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec51b720-a50f-4409-9efd-9e9f29035d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#我们可以利用cross entropy的库函数来简化这个过程\n",
    "#注：该函数内部自带一次softmax的激活函数\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f348b80f-44e0-493d-aed9-1a89a8a21be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873fdf90-7dc5-4e39-a666-c5524a33751f",
   "metadata": {},
   "source": [
    "## 文本评估函数 cross entrpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8695fe2-2431-4f56-966a-eccb57a67c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.5722)\n"
     ]
    }
   ],
   "source": [
    "#直接应用cross entropy函数\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat,targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0655f3-17af-47d4-b4e7-2cd91f1c4423",
   "metadata": {},
   "source": [
    "# Perplexity \n",
    "是一种经常与交叉熵损失一起使用的指标，用于评估语言建模等任务中的模型表现。它能够以更具可解释性的方式，帮助理解模型在预测下一个 token 时的不确定性。计算公式为perplexity = torch.exp(loss)，对先前计算的损失值应用此公式将返回 tensor(48725.8203)\n",
    "可解释性：这就意味这在下一个单词预测可能有40725种可能，如果这个值为1那么说明这个预测效果特别好，只有一个单词的可能性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fc4640-e5cb-47d9-903e-527ca840b4d8",
   "metadata": {},
   "source": [
    "## 计算训练集和验证集的损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d6ba0b7-d489-46d1-945f-ee87174604f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./The_Verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfeb5b3b-4816-4478-9e1e-147ac6f6e8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 21941\n",
      "Tokens: 5560\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e894e5a4-8ea2-4440-b8d0-08d56ae6c8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19746\n"
     ]
    }
   ],
   "source": [
    "#定义一个train_ratio , 90%用于训练 10%用于测试\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "print(len(train_data))\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502c72a0-7556-4cce-b362-4e0489774b99",
   "metadata": {},
   "source": [
    "1. 测试集不需要 drop_last\n",
    "drop_last=True 的含义是在批次（batch）的最后，如果数据不足以填满一个完整的批次（即剩余的数据量小于 batch_size），则丢弃这一部分数据。\n",
    "\n",
    "训练阶段：在训练时，我们可能会有数千、甚至数百万个批次来更新模型参数。如果最后一个批次的数据量少于 batch_size，可能会导致批次不均衡，影响梯度的更新。在这种情况下，使用 drop_last=True 确保每个批次的大小一致，有助于更稳定的梯度计算和模型更新。\n",
    "\n",
    "验证/测试阶段：在验证集或测试集中，我们通常需要评估模型在整个数据集上的性能。每一个样本的输出都是重要的，即使最后一个批次的大小不满 batch_size，我们也需要保留所有数据进行评估。因此，在验证集上我们设置 drop_last=False，不会丢弃最后一个不满 batch_size 的小批次，以确保在验证过程中使用所有数据。\n",
    "2. 测试集不需要 shuffle\n",
    "shuffle=True 表示在每个 epoch 之前随机打乱数据集的顺序，这在训练阶段非常重要。\n",
    "\n",
    "训练阶段：在训练时，我们通过 shuffle=True 来打乱数据顺序，以避免模型在学习过程中对数据集的顺序产生依赖或出现过拟合（overfitting）问题。通过打乱顺序，模型可以更好地学习到数据的泛化模式。\n",
    "\n",
    "验证/测试阶段：在验证或测试时，数据集的顺序并不影响模型评估，因为我们仅关心模型在整个数据集上的准确性和性能表现，顺序不会改变模型的预测结果。因此，在测试集上我们通常使用 shuffle=False，以确保数据是按照其原始顺序传递给模型，同时也提高了验证过程的确定性和可复现性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b4a2d87-c384-4f99-ad3a-b592c3a00d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "4970\n",
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "token_ids = tokenizer.encode(train_data)\n",
    "print(len(train_loader))\n",
    "print(len(token_ids))\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4554463a-a47e-4129-93ae-27a6edd689e8",
   "metadata": {},
   "source": [
    "#其实我们可以看出一本40000多字的文章，有效的token只有5000多个，9个2*256大约就是4608个token，其余的被dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c4afff2-aeb5-4d65-8292-d3c5d346f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#封装一个用于计算输入batch cross entropy的loss函数\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)       #A\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0528d604-bfd2-45dc-bc2e-abda49cb45b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#封装一个用于计算dataloader 的loss 函数\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))                  #B\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()                                     #C\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches                                       #D  \n",
    "#A 如果没有指定批次数，将自动遍历所有批次\n",
    "#B 若批次数超过数据加载器的总批次数，则减少批次数使其与数据加载器的批次数相匹配\n",
    "#C 每个批次的损失求和\n",
    "#D 对所有批次的损失取平均值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef24f96-05ed-4d5c-b7f2-8ec7b1949ffb",
   "metadata": {},
   "source": [
    "#注：这里可能会疑惑对批次数量的定义,到底是输出9个张量的批次还是在dataloader中定义的batch_size=2,很容易混淆这两个概念。实际上batch_size指的是批次的大小也就是每个批次样本数量。批次数量的定义是：\n",
    "    批次数量= batch_size/总样本数量\n",
    "此外最后输出的total_loss 别忘了要除以批次数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a938bd7-c9fc-4ca6-b59f-acf321c8aa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.980390866597494\n",
      "Validation loss: 11.006519317626953\n"
     ]
    }
   ],
   "source": [
    "#计算一下训练集的loss值\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "with torch.no_grad():                                                 #B\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)        #C\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06117d8f-1305-4fb5-a548-9e0020fc0db0",
   "metadata": {},
   "source": [
    "#上面的model我们一直使用的是初始化的权重计算loss值，所以非常高接下来我们开始训练model\n",
    "训练model的框架\n",
    "for each training epoch：\n",
    "    for each batch in training set:\n",
    "        reset loss gradients from previous epoch\n",
    "        calculate loos on current batch\n",
    "        backward pass to calculate loss gradients\n",
    "        update model weights using loss gradients\n",
    "        print training and validation set losses(optional)\n",
    "    generate sample text for visual inspection(optional)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eced51be-2d31-433b-8b67-f335792a00e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \")) # Compact print format\n",
    "    model.train()\n",
    "    \n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()                #A\n",
    "    with torch.no_grad():       #B\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "#A 评估阶段禁用 dropout，以确保结果稳定、可复现\n",
    "#B 禁用梯度跟踪，减少计算开销\n",
    "\n",
    "\n",
    "# Listing 5.3 The main function for pretraining LLMs\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []                        #A\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):                                                 #B\n",
    "        model.train() #设置为训练模式，所以梯度计算和dropout将会激活\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()                                                   #C\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()                                                         #D\n",
    "            optimizer.step()                                                        #E\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:                                        #F\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        generate_and_print_sample(                                                  #G\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "#A 初始化用于记录损失和已处理 token 数量的列表\n",
    "#B 开始主训练循环\n",
    "#C 重置上一批次的损失梯度\n",
    "#D 计算损失梯度\n",
    "#E 使用损失梯度更新模型权重\n",
    "#F 可选的评估步骤\n",
    "#G 每个 epoch 结束后打印示例文本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3952e597-fb6d-4a47-a32c-d684d24f659a",
   "metadata": {},
   "source": [
    "#if global_step % eval_freq == 0:  \n",
    "这个是定义一个评估频率，批次处理中如果每次批次处理都进行评估可能会浪费运算资源，所以一般在神经网络训练框架中会设置一个评估频率。\n",
    "#每次epoch的训练数据其实是不一样的，因为train_loader 是一个来自 PyTorch 的 DataLoader 对象，且在初始化时设置了 shuffle=True，那么每次遍历 train_loader 时，数据都会在每个 epoch 之间进行打乱。如果 shuffle=False，则数据的顺序会保持不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e5728b4-a5e9-4314-bb5f-ab6233d25040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.989, Val loss 10.023\n",
      "Ep 1 (Step 000005): Train loss 8.290, Val loss 8.725\n",
      "Every effort moves you                                                  \n",
      "Ep 2 (Step 000010): Train loss 6.819, Val loss 7.842\n",
      "Ep 2 (Step 000015): Train loss 5.922, Val loss 7.812\n",
      "Every effort moves you.                                                 \n",
      "Ep 3 (Step 000020): Train loss 14.185, Val loss 13.097\n",
      "Ep 3 (Step 000025): Train loss 5.563, Val loss 7.950\n",
      "Every effort moves you to the                                                \n",
      "Ep 4 (Step 000030): Train loss 5.508, Val loss 8.068\n",
      "Ep 4 (Step 000035): Train loss 4.781, Val loss 7.783\n",
      "Every effort moves you.                                                 \n",
      "Ep 5 (Step 000040): Train loss 5.182, Val loss 7.913\n",
      "Every effort moves you, and, as the picture, and, as his painting.                                     \n",
      "Ep 6 (Step 000045): Train loss 5.108, Val loss 7.744\n",
      "Ep 6 (Step 000050): Train loss 3.140, Val loss 7.754\n",
      "Every effort moves you know the      \"I was his pictures--and a little of his pictures of his pictures, and, and distinguished objects, and my dear fellow--I, and I was not him, and I was. Gisburn\n",
      "Ep 7 (Step 000055): Train loss 3.980, Val loss 7.745\n",
      "Ep 7 (Step 000060): Train loss 3.512, Val loss 7.643\n",
      "Every effort moves you know, I had the fact, I had the dim, I had been the donkey, I had been to the fact, and on the fact, in the fact his pictures--as he had been the fact, and I had been the end the\n",
      "Ep 8 (Step 000065): Train loss 3.163, Val loss 7.670\n",
      "Ep 8 (Step 000070): Train loss 2.380, Val loss 7.765\n",
      "Every effort moves you know on the threshold.                    \"Never think of it, the dim fellow--I H the donkey.          \n",
      "Ep 9 (Step 000075): Train loss 1.480, Val loss 7.751\n",
      "Ep 9 (Step 000080): Train loss 1.547, Val loss 7.801\n",
      "Every effort moves you me before, with such a tempting problem.  \"Oh, in the pockets of his eyes: \"We as he had been, with a little       \"Oh, and my a little too? I didn't\n",
      "Ep 10 (Step 000085): Train loss 1.049, Val loss 7.845\n",
      "Every effort moves you know after.    \"Oh, and his cheeks paled a little under their handsome sunburn's welcome was, as he was, in the ensuing weeks, I could never have been through, and in the picture. Gisburn\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)      #A\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=1,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "#A .parameters() 方法返回模型的所有可训练权重参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ba826e7-7200-4b10-a761-ff2495b53808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAEiCAYAAADkhpu7AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYw9JREFUeJzt3Xd4FFXbwOHf7iab3kgPIaGFBEISOtIEBA2ISBVFRJrYQEFsr6+CgJ9iQfRVEMUCKihWEJWOFOk1kNBrQkmhpPfszvfHJBsWQgkk2WR57uvaK7szZ2aenST77Dlz5hyNoigKQgghhLAaWksHIIQQQoiKJcldCCGEsDKS3IUQQggrI8ldCCGEsDKS3IUQQggrI8ldCCGEsDKS3IUQQggrI8ldCCGEsDKS3IUQQggrI8ldiDvUqVOn0Gg0xMTEWDoUIUQFk+QuRA2m0Wiu+5g8ebKlQxRCWICNpQMQQty6xMRE0/OffvqJSZMmcfjwYdMyZ2dnS4QlhLAwqbkLUYP5+fmZHm5ubmg0GtNrHx8fZsyYQWBgIHZ2djRr1ozly5dfc18Gg4GRI0cSFhZGQkICAH/88QctWrTA3t6e+vXrM2XKFIqKikzbaDQavvrqK/r164ejoyMhISEsWbLEtD41NZUhQ4bg7e2Ng4MDISEhzJ0795ox/Prrr0RERODg4ICnpyfdu3cnOzvbtP6rr76icePG2NvbExYWxmeffWa2/enTpxk0aBDu7u7UqlWLPn36cOrUKdP64cOH07dvX6ZPn46/vz+enp6MGTOGwsLCmz7nQtQIihDCKsydO1dxc3MzvZ4xY4bi6uqq/Pjjj8qhQ4eUV155RbG1tVWOHDmiKIqinDx5UgGUPXv2KHl5eUq/fv2U5s2bKykpKYqiKMqGDRsUV1dXZd68ecrx48eVlStXKnXr1lUmT55sOgagBAYGKj/88INy9OhR5fnnn1ecnZ2VixcvKoqiKGPGjFGaNWum7NixQzl58qSyatUqZcmSJWXGf+7cOcXGxkaZMWOGcvLkSWXfvn3KrFmzlMzMTEVRFGX+/PmKv7+/8ttvvyknTpxQfvvtN6VWrVrKvHnzFEVRlIKCAqVx48bKyJEjlX379ikHDhxQHn30USU0NFTJz89XFEVRhg0bpri6uipPP/20cvDgQeXPP/9UHB0dlTlz5lTsL0MIC5PkLoSVuDK5BwQEKG+//bZZmdatWyvPPvusoiilyf3ff/9VunXrpnTs2FFJS0szle3WrZvyzjvvmG3//fffK/7+/qbXgPLGG2+YXmdlZSmAsmzZMkVRFKV3797KiBEjbir+Xbt2KYBy6tSpMtc3aNBA+eGHH8yWvfXWW0q7du1MsYWGhipGo9G0Pj8/X3FwcFBWrFihKIqa3IODg5WioiJTmYceekh5+OGHbypGIWoKueYuhBXKyMjg3LlzdOjQwWx5hw4d2Lt3r9mywYMHExgYyD///IODg4Np+d69e9m0aRNvv/22aZnBYCAvL4+cnBwcHR0BiIyMNK13cnLC1dWVlJQUAJ555hkGDBjA7t27ue++++jbty/t27cvM+aoqCi6detGREQE0dHR3HfffQwcOBAPDw+ys7M5fvw4o0aNYvTo0aZtioqKcHNzM8V77NgxXFxczPabl5fH8ePHTa/Dw8PR6XSm1/7+/sTGxl7nbApR80hyF+IOd//99zN//ny2bNnCPffcY1qelZXFlClT6N+//1Xb2Nvbm57b2tqardNoNBiNRgB69uxJfHw8S5cuZdWqVXTr1o0xY8Ywffr0q/ap0+lYtWoVmzdvZuXKlXz66ae8/vrrbNu2zfRF4ssvv6Rt27ZXbVcSb8uWLVmwYMFV+/b29r6peIWwFpLchbBCrq6uBAQEsGnTJjp37mxavmnTJtq0aWNW9plnnqFp06Y8+OCD/P3336byLVq04PDhwzRs2PC2YvH29mbYsGEMGzaMTp068fLLL5eZ3EFNtB06dKBDhw5MmjSJ4OBgFi1axIQJEwgICODEiRMMGTKkzG1btGjBTz/9hI+PD66urrcVsxA1nSR3IazUyy+/zJtvvkmDBg1o1qwZc+fOJSYmpsya7XPPPYfBYOCBBx5g2bJldOzYkUmTJvHAAw8QFBTEwIED0Wq17N27l7i4OP7v//7vpmKYNGkSLVu2JDw8nPz8fP766y8aN25cZtlt27axZs0a7rvvPnx8fNi2bRvnz583lZ8yZQrPP/88bm5u9OjRg/z8fHbu3ElqaioTJkxgyJAhfPDBB/Tp04epU6cSGBhIfHw8v//+O6+88gqBgYG3fjKFqGEkuQthpZ5//nnS09N58cUXSUlJoUmTJixZsoSQkJAyy48fPx6j0cj999/P8uXLiY6O5q+//mLq1Km899572NraEhYWxhNPPHHTMej1el577TVOnTqFg4MDnTp1YuHChWWWdXV1ZcOGDXz88cdkZGQQHBzMhx9+SM+ePQF44okncHR05IMPPuDll1/GycmJiIgIxo8fD4CjoyMbNmzg1VdfpX///mRmZlK7dm26desmNXlxx9EoiqJYOgghhBBCVBwZxEYIIYSwMpLchRBCCCsjyV0IIYSwMpLchRBCCCsjyV0IIYSwMpLchRBCCCsjyb0CzZo1i7p162Jvb0/btm3Zvn27pUOqFjZs2EDv3r0JCAhAo9GwePFis/WKojBp0iT8/f1xcHCge/fuHD161KzMpUuXGDJkCK6urri7uzNq1CiysrLMyuzbt49OnTphb29PnTp1eP/996+K5ZdffiEsLAx7e3siIiJYunRphb/fqjZt2jRat26Ni4sLPj4+9O3b12xOd1DHVx8zZgyenp44OzszYMAAkpOTzcokJCTQq1cvHB0d8fHx4eWXXzab3hVg3bp1tGjRAjs7Oxo2bMi8efOuisfa/g9mz55NZGQkrq6uuLq60q5dO5YtW2ZaL+e2Yr377rtoNBrT+AUg5/iWWHjiGquxcOFCRa/XK998842yf/9+ZfTo0Yq7u7uSnJxs6dAsbunSpcrrr7+u/P777wqgLFq0yGz9u+++q7i5uSmLFy9W9u7dqzz44INKvXr1lNzcXFOZHj16KFFRUcrWrVuVf//9V2nYsKEyePBg0/r09HTF19dXGTJkiBIXF6f8+OOPioODg/LFF1+YymzatEnR6XTK+++/rxw4cEB54403FFtbWyU2NrbSz0Flio6OVubOnavExcUpMTExyv33368EBQUpWVlZpjJPP/20UqdOHWXNmjXKzp07lbvuuktp3769aX1RUZHStGlTpXv37sqePXuUpUuXKl5eXsprr71mKnPixAnF0dFRmTBhgnLgwAHl008/VXQ6nbJ8+XJTGWv8P1iyZIny999/K0eOHFEOHz6s/Pe//1VsbW2VuLg4RVHk3Fak7du3K3Xr1lUiIyOVcePGmZbLOS4/Se4VpE2bNsqYMWNMrw0GgxIQEKBMmzbNglFVP1cmd6PRqPj5+SkffPCBaVlaWppiZ2en/Pjjj4qiKMqBAwcUQNmxY4epzLJlyxSNRqOcPXtWURRF+eyzzxQPDw/TvN2KoiivvvqqEhoaano9aNAgpVevXmbxtG3bVnnqqacq9D1aWkpKigIo69evVxRFPZ+2trbKL7/8Yipz8OBBBVC2bNmiKIr6BUyr1SpJSUmmMrNnz1ZcXV1N5/SVV15RwsPDzY718MMPK9HR0abXd8r/gYeHh/LVV1/Jua1AmZmZSkhIiLJq1Sqlc+fOpuQu5/jWSLN8BSgoKGDXrl10797dtEyr1dK9e3e2bNliwciqv5MnT5KUlGR27tzc3Gjbtq3p3G3ZsgV3d3datWplKtO9e3e0Wi3btm0zlbn77rvR6/WmMtHR0Rw+fJjU1FRTmcuPU1LG2n5H6enpANSqVQuAXbt2UVhYaPbew8LCCAoKMjvHERER+Pr6mspER0eTkZHB/v37TWWud/7uhP8Dg8HAwoULyc7Opl27dnJuK9CYMWPo1avXVedBzvGtkbHlK8CFCxcwGAxmf1gAvr6+HDp0yEJR1QxJSUkAZZ67knVJSUn4+PiYrbexsaFWrVpmZerVq3fVPkrWeXh4kJSUdN3jWAOj0cj48ePp0KEDTZs2BdT3r9frcXd3Nyt75Tku69yUrLtemYyMDHJzc0lNTbXa/4PY2FjatWtHXl4ezs7OLFq0iCZNmhATEyPntgIsXLiQ3bt3s2PHjqvWyd/vrZHkLoQVGTNmDHFxcWzcuNHSoViV0NBQYmJiSE9P59dff2XYsGGsX7/e0mFZhdOnTzNu3DhWrVqFvb29pcOxGtIsXwG8vLzQ6XRX9d5MTk7Gz8/PQlHVDCXn53rnzs/Pj5SUFLP1RUVFXLp0yaxMWfu4/BjXKmMtv6OxY8fy119/sXbtWrPpTf38/CgoKCAtLc2s/JXn+FbPn6urKw4ODlb9f6DX62nYsCEtW7Zk2rRpREVF8b///U/ObQXYtWsXKSkptGjRAhsbG2xsbFi/fj2ffPIJNjY2+Pr6yjm+BZLcK4Ber6dly5asWbPGtMxoNLJmzRratWtnwciqv3r16uHn52d27jIyMti2bZvp3LVr1460tDR27dplKvPPP/9gNBpp27atqcyGDRsoLCw0lVm1ahWhoaF4eHiYylx+nJIyNf13pCgKY8eOZdGiRfzzzz9XXZ5o2bIltra2Zu/98OHDJCQkmJ3j2NhYsy9Rq1atwtXVlSZNmpjKXO/83Un/B0ajkfz8fDm3FaBbt27ExsYSExNjerRq1YohQ4aYnss5vgWW7tFnLRYuXKjY2dkp8+bNUw4cOKA8+eSTiru7u1nvzTtVZmamsmfPHmXPnj0KoMyYMUPZs2ePEh8fryiKeiucu7u78scffyj79u1T+vTpU+atcM2bN1e2bdumbNy4UQkJCTG7FS4tLU3x9fVVhg4dqsTFxSkLFy5UHB0dr7oVzsbGRpk+fbpy8OBB5c0337SKW+GeeeYZxc3NTVm3bp2SmJhoeuTk5JjKPP3000pQUJDyzz//KDt37lTatWuntGvXzrS+5Fai++67T4mJiVGWL1+ueHt7l3kr0csvv6wcPHhQmTVrVpm3Elnb/8F//vMfZf369crJkyeVffv2Kf/5z38UjUajrFy5UlEUObeV4fLe8ooi5/hWSHKvQJ9++qkSFBSk6PV6pU2bNsrWrVstHVK1sHbtWgW46jFs2DBFUdTb4SZOnKj4+voqdnZ2Srdu3ZTDhw+b7ePixYvK4MGDFWdnZ8XV1VUZMWKEkpmZaVZm7969SseOHRU7Ozuldu3ayrvvvntVLD///LPSqFEjRa/XK+Hh4crff/9dae+7qpR1bgFl7ty5pjK5ubnKs88+q3h4eCiOjo5Kv379lMTERLP9nDp1SunZs6fi4OCgeHl5KS+++KJSWFhoVmbt2rVKs2bNFL1er9SvX9/sGCWs7f9g5MiRSnBwsKLX6xVvb2+lW7dupsSuKHJuK8OVyV3OcflpFEVRLNNmIIQQQojKINfchRBCCCsjyV0IIYSwMpLchRBCCCsjyV0IIYSwMpLchRBCCCsjyV0IIYSwMpLcK1h+fj6TJ08mPz/f0qFYJTm/lUvOb+WTc1y55Pyq5D73CpaRkYGbmxvp6em4urpaOhyrI+e3csn5rXxyjiuXnF+V1NyFEEIIKyPJXQghhLAyMp97GYqKitizZw++vr5oteX7/pOZmQnA2bNnycjIqIzw7mhyfiuXnN/KJ+e4clnz+TUajSQnJ9O8eXNsbK6fvuWaexl27NhBmzZtLB2GEEIIcZXt27fTunXr65aRmnsZfH19AfUE+vv7WzgaIYQQAhITE2nTpo0pR12PJPcylDTF+/v7ExgYaOFohBBCiFI3c7lYOtQJIYQQVkaSuxBCCGFlJLkLIYQQVkauuQshxG0yGAwUFhZaOgxRw9na2qLT6SpkX5LchdU4dSEbT2c9Lva2lg5F3CEURSEpKYm0tDRLhyKshLu7O35+fmg0mtvajyR3YRX2n0vnwZmbuCfMhy8fb2XpcMQdoiSx+/j44OjoeNsfyOLOpSgKOTk5pKSkANz2bdiS3IVV2HDkAgajwr9Hz1NkMGKjk+4konIZDAZTYvf09LR0OMIKODg4AJCSkoKPj89tNdHLJ6CwCntPpwGQV2jk2PksywYj7ggl19gdHR0tHImwJiV/T7fbh0OSu7AKMcXJHWDfmXTLBSLuONIULypSRf09SXIXNV5Seh5JGXmm17GS3IUQdzhJ7qLG23smzez1vrOS3IWoanXr1uXjjz++6fLr1q1Do9FU+p0G8+bNw93dvVKPUR1Jchc1XkmTfPsGaqemg4kZFBQZLRiRENWXRqO57mPy5Mm3tN8dO3bw5JNP3nT59u3bk5iYiJub2y0dT1yf9JYXNV5JZ7reUQHEnU0nI6+II8mZNK0tHxpCXCkxMdH0/KeffmLSpEkcPnzYtMzZ2dn0XFEUDAbDDecOB/D29i5XHHq9Hj8/v3JtI26e1NxFjWY0KqYOdM3quBMZ6A5IpzohrsXPz8/0cHNzQ6PRmF4fOnQIFxcXli1bRsuWLbGzs2Pjxo0cP36cPn364Ovri7OzM61bt2b16tVm+72yWV6j0fDVV1/Rr18/HB0dCQkJYcmSJab1VzbLlzSfr1ixgsaNG+Ps7EyPHj3MvowUFRXx/PPP4+7ujqenJ6+++irDhg2jb9++5ToHs2fPpkGDBuj1ekJDQ/n+++9N6xRFYfLkyQQFBWFnZ0dAQADPP/+8af1nn31GSEgI9vb2+Pr6MnDgwHIdu6pIchc12vHzWWTlF+FgqyPEx5mIQLW2Hns2zbKBiTuSoijkFBRZ5KEoSoW9j//85z+8++67HDx4kMjISLKysrj//vtZs2YNe/bsoUePHvTu3ZuEhITr7mfKlCkMGjSIffv2cf/99zNkyBAuXbp0zfI5OTlMnz6d77//ng0bNpCQkMBLL71kWv/ee++xYMEC5s6dy6ZNm8jIyGDx4sXlem+LFi1i3LhxvPjii8TFxfHUU08xYsQI1q5dC8Bvv/3GRx99xBdffMHRo0dZvHgxERERAOzcuZPnn3+eqVOncvjwYZYvX87dd99druNXFWmWFzVayfX2iEA3bHRaIoub4qXmLiwht9BAk0krLHLsA1OjcdRXzEf61KlTuffee02va9WqRVRUlOn1W2+9xaJFi1iyZAljx4695n6GDx/O4MGDAXjnnXf45JNP2L59Oz169CizfGFhIZ9//jkNGjQAYOzYsUydOtW0/tNPP+W1116jX79+AMycOZOlS5eW671Nnz6d4cOH8+yzzwIwYcIEtm7dyvTp0+natSsJCQn4+fnRvXt3bG1tCQoKok2bNgAkJCTg5OTEAw88gIuLC8HBwTRv3rxcx68qUnMXNVpJT/lmddwBiCz+eTgpk7xCg2WCEqKGa9XKfAjnrKwsXnrpJRo3boy7uzvOzs4cPHjwhjX3yMhI03MnJydcXV1Nw6uWxdHR0ZTYQR2CtaR8eno6ycnJpkQLoNPpaNmyZbne28GDB+nQoYPZsg4dOnDw4EEAHnroIXJzc6lfvz6jR49m0aJFFBUVAXDvvfcSHBxM/fr1GTp0KAsWLCAnJ6dcx68qUnMXNVpJzT2q+Fp7gJs9nk56LmYXcCgp05T0hagKDrY6DkyNttixK4qTk5PZ65deeolVq1Yxffp0GjZsiIODAwMHDqSgoOC6+7G1NZ/ESaPRYDRe+06WsspX5OWGm1GnTh0OHz7M6tWrWbVqFc8++ywffPAB69evx8XFhd27d7Nu3TpWrlzJpEmTmDx5Mjt27Kh2t9tJzV3UWHmFBg4lZgLQLMgdUD8MTNfdr7j/XYjKptFocNTbWORRmSPlbdq0ieHDh9OvXz8iIiLw8/Pj1KlTlXa8sri5ueHr68uOHTtMywwGA7t37y7Xfho3bsymTZvMlm3atIkmTZqYXjs4ONC7d28++eQT1q1bx5YtW4iNjQXAxsaG7t278/7777Nv3z5OnTrFP//8cxvvrHJIzV3UWPvPZVBkVPBytiPAzd60PLK2G+sOn5fr7kJUkJCQEH7//Xd69+6NRqNh4sSJ162BV5bnnnuOadOm0bBhQ8LCwvj0009JTU0t1xebl19+mUGDBtG8eXO6d+/On3/+ye+//27q/T9v3jwMBgNt27bF0dGR+fPn4+DgQHBwMH/99RcnTpzg7rvvxsPDg6VLl2I0GgkNDa2st3zLJLmLGqukSb5ZHfV2HhQFkvbRwksPQKyMVCdEhZgxYwYjR46kffv2eHl58eqrr5KRkVHlcbz66qskJSXx+OOPo9PpePLJJ4mOji7X7Gl9+/blf//7H9OnT2fcuHHUq1ePuXPn0qVLF0CdT/3dd99lwoQJGAwGIiIi+PPPP/H09MTd3Z3ff/+dyZMnk5eXR0hICD/++CPh4eGV9I5vnUap6gsaNcCZM2eoU6cOp0+fJjAw0NLhiGt4/sc9LNl7jpfubchYz90Q9yscW01m5ylErAhBq4H9U3rgoK+4a5FClMjLy+PkyZPUq1cPe3v7G28gKpzRaKRx48YMGjSIt956y9LhVIjr/V2VJzdJzV3UWCU95TvZH4fFT6sLtba4GDPwcbEjJTOfA4nptAyuZbkghRAVJj4+npUrV9K5c2fy8/OZOXMmJ0+e5NFHH7V0aNWORTvUbdiwgd69exMQEIBGozEbjKCwsJBXX32ViIgInJycCAgI4PHHH+fcuXPX3efkyZOvGis5LCyskt+JqGqXsguIv6jeghJ2qbgzS9gD8OpJ6DaJyEC5310Ia6PVapk3bx6tW7emQ4cOxMbGsnr1aho3bmzp0Kodi9bcs7OziYqKYuTIkfTv399sXU5ODrt372bixIlERUWRmprKuHHjePDBB9m5c+d19xseHm42NOLNjIssapaSWnsDLwfsjvylLmz+GNi5ABBR253VB1Nk+lchrEidOnWu6ukuymbRrNezZ0969uxZ5jo3NzdWrVpltmzmzJm0adOGhIQEgoKCrrlfGxsbmZDAypVMFtPX8wzEJ4KdKzS4x7S+jbt6i5xM/yqEuBPVqPvc09PT0Wg0Nxws4OjRowQEBFC/fn2GDBlyw1GU8vPzycjIMD0yMzMrMGpRGUp6yndTtqgLQnuCjR0YimBOV9r91ZV6mkTT2PNCCHEnqTHJPS8vj1dffZXBgwfj6up6zXJt27Zl3rx5LF++nNmzZ3Py5Ek6dep03YQ9bdo03NzcTI/LBzMQ1Y+iKOw9nYYGIyEX1qgLm/RVf+pswMEDgMGOO1AU2C+1dyHEHaZGJPfCwkIGDRqEoijMnj37umV79uzJQw89RGRkJNHR0SxdupS0tDR+/vnna27z2muvkZ6ebnocOHCgot+CqECnL+WSmlNIW5vj2OYkg97FrEmepmr/jV7arYB0qhNC3HmqfXIvSezx8fGsWrXqurX2sri7u9OoUSOOHTt2zTJ2dna4urqaHi4uLrcbtqhEe06nAvCoS/Gwk6E9wfay+0HDHgCtLbULTxGiOSPX3YUQd5xqndxLEvvRo0dZvXo1np6e5d5HVlYWx48fx9/fvxIiFJaw93Q6Gox0KdqsLgjva17AwR0adgfgAd0WGWNeCHHHsWhyz8rKIiYmhpiYGABOnjxJTEwMCQkJFBYWMnDgQHbu3MmCBQswGAwkJSWRlJRkNhNRt27dmDlzpun1Sy+9xPr16zl16hSbN2+mX79+6HQ605zCoubbeyaN5ppjuBaeL26S73Z1oeKm+d7aLZy6mE16TmEVRymEdevSpQvjx483va5bty4ff/zxdbe5cjyTW1VR+7meyZMn06xZs0o9RmWyaHLfuXMnzZs3N012P2HCBJo3b86kSZM4e/YsS5Ys4cyZMzRr1gx/f3/TY/PmzaZ9HD9+nAsXLphenzlzhsGDBxMaGsqgQYPw9PRk69ateHt7V/n7ExWv0GAk7mw6vXTb1AWhPcyb5EuE9gQbe+prkwjXxBN3TprmhQDo3bs3PXr0KHPdv//+i0ajYd++feXe744dO3jyySdvNzwz10qwiYmJ17yNWqgsep97ly5drjtX780Me3/ltIMLFy683bBENXY4KZOCoiJ62W9XF5T0kr+SnQuE3AcHl/CAbgv7zvSgQ0OvKotTiOpq1KhRDBgwgDNnzlw1PvncuXNp1aoVkZGR5d5vVVagZByTG6vW19yFuFLM6TS0KPzq+RQ0HQgNy2iSL1HcNP+AdiuxZ1KrKEIhqrcHHngAb29v5s2bZ7Y8KyuLX375hVGjRnHx4kUGDx5M7dq1cXR0JCIigh9//PG6+72yWf7o0aPcfffd2Nvb06RJk6sGJQN1lrdGjRrh6OhI/fr1mThxIoWF6iW0efPmMWXKFPbu3WsaSrwk5iub5WNjY7nnnntwcHDA09OTJ598kqysLNP64cOH07dvX6ZPn46/vz+enp6MGTPGdKybYTQamTp1KoGBgdjZ2dGsWTOWL19uWl9QUMDYsWPx9/fH3t6e4OBgpk2bBqgV1cmTJxMUFISdnR0BAQE8//zzN33sWyHjsooaJeZ0GgZ05If2hftuMIdySDQGG0fqFJ2n8PROoFVVhCgEFGSXfxudnTpOA6iDMRnyQaMFW4cb71fvdNOHsbGx4fHHH2fevHm8/vrrprnQf/nlFwwGA4MHDyYrK4uWLVvy6quv4urqyt9//83QoUNp0KABbdq0ueExjEYj/fv3x9fXl23btpGenm52fb6Ei4sL8+bNIyAggNjYWEaPHo2LiwuvvPIKDz/8MHFxcSxfvtw0nLibm9tV+8jOziY6Opp27dqxY8cOUlJSeOKJJxg7dqzZF5i1a9fi7+/P2rVrOXbsGA8//DDNmjVj9OjRN3Xe/ve///Hhhx/yxRdf0Lx5c7755hsefPBB9u/fT0hICJ988glLlizh559/JigoiNOnT3P69GkAfvvtNz766CMWLlxIeHg4SUlJ7N2796aOe6skuYsaZa9pDnf3GxfWO2IMiUZ3cBFts9dxKXsktZz0lRqfEAC8E1D+bR6aB+H91OeH/oRfhkNwRxjxd2mZjyMg5+LV204uX5+SkSNH8sEHH7B+/XrTPOZz585lwIABpsG8XnrpJVP55557jhUrVvDzzz/fVHJfvXo1hw4dYsWKFQQEqOfinXfeueo6+RtvvGF6XrduXV566SUWLlzIK6+8goODA87OzjccTvyHH34gLy+P7777Dicn9UvOzJkz6d27N++99x6+vr4AeHh4MHPmTHQ6HWFhYfTq1Ys1a9bcdHKfPn06r776Ko888ggA7733HmvXruXjjz9m1qxZJCQkEBISQseOHdFoNAQHB5u2TUhIwM/Pj+7du2Nra0tQUNBNncfbIc3yosbIzCvE5sIBxuoW0dzxwo03AGyjHgKgl26bNM0LUSwsLIz27dvzzTffAHDs2DH+/fdfRo0aBYDBYOCtt94iIiKCWrVq4ezszIoVK244lHeJgwcPUqdOHVNiB2jXrt1V5X766Sc6dOiAn58fzs7OvPHGGzd9jMuPFRUVZUrsAB06dMBoNHL48GHTsvDwcHQ6nem1v78/KSkpN3WMjIwMzp07R4cOHcyWd+jQgYMHDwJq039MTAyhoaE8//zzrFy50lTuoYceIjc3l/r16zN69GgWLVpEUVHlDostNXdRY8SeSaef9l+etPkbdhgh+Jsbb9SwO8n6OqzMCSMvPpHOob6VH6gQ/73+1NRl0tmVPg/rre5Dc0X9a3zs7cV1mVGjRvHcc88xa9Ys5s6dS4MGDejcuTMAH3zwAf/73//4+OOPTdNujx8/3uw25Nu1ZcsWhgwZwpQpU4iOjsbNzY2FCxfy4YcfVtgxLmdra2v2WqPRYDQaK2z/LVq04OTJkyxbtozVq1czaNAgunfvzq+//kqdOnU4fPgwq1evZtWqVTz77LOmlpMr46ooUnMXNUbMmTR2GUPY79hG7Ux3M2zs+LPjH7xZNIJdSTKBjKgieqfyP3SX1bV0Nuqyy6+3X2+/t2DQoEFotVp++OEHvvvuO0aOHGm6/r5p0yb69OnDY489RlRUFPXr1+fIkSM3ve/GjRtz+vRpEhMTTcu2bt1qVmbz5s0EBwfz+uuv06pVK0JCQoiPjzd/u3o9BoPhhsfau3cv2dml/RE2bdqEVqslNPQG/XJukqurKwEBAVdNN7tp0yazuUhcXV15+OGH+fLLL/npp5/47bffuHTpEgAODg707t2bTz75hHXr1rFlyxZiYyvuy9qVpOYuaoy9p9NYYWxDq7uGER5W/6a3i6yjTiQTK8PQCmHi7OzMww8/zGuvvUZGRgbDhw83rQsJCeHXX39l8+bNeHh4MGPGDJKTk296Uq3u3bvTqFEjhg0bxgcffEBGRgavv/66WZmQkBASEhJYuHAhrVu35u+//2bRokVmZerWrWsa3CwwMBAXFxfs7OzMygwZMoQ333yTYcOGMXnyZM6fP89zzz3H0KFDTdfbK8LLL7/Mm2++SYMGDWjWrBlz584lJiaGBQsWADBjxgz8/f1p3rw5Wq2WX375BT8/P9zd3Zk3bx4Gg4G2bdvi6OjI/PnzcXBwMLsuX9Gk5i5qjJJpXqNupjPdZcIDXNFqjNTJ2MPFU+UfnEMIazVq1ChSU1OJjo42uz7+xhtv0KJFC6Kjo+nSpQt+fn707dv3pver1WpZtGgRubm5tGnThieeeIK3337brMyDDz7ICy+8wNixY2nWrBmbN29m4sSJZmUGDBhAjx496Nq1K97e3mXejufo6MiKFSu4dOkSrVu3ZuDAgVeNXFoRnn/+eSZMmMCLL75IREQEy5cvZ8mSJYSEhABqz//333+fVq1a0bp1a06dOsXSpUvRarW4u7vz5Zdf0qFDByIjI1m9ejV//vnnLQ2pfrM0ys2MFHOHOXPmDHXq1OH06dNXDfIgLCMpLZdPP/gv65UWrJw8GEd9+Rqdfn3ncQYW/MHZBg9Te+icSopS3Eny8vI4efIk9erVw96+jFEShbgF1/u7Kk9ukpq7qBFO7PuXt22/YaX+ZRy1178GV5bzfneTrjiSmCtXooQQ1k+Su6gRtAf/AOCYWzuwsbtB6as5NupC6/zZfKYfUdGhCSFEtSPJXVR/ikL9FHXoyoz6vW5pFxFBnhRgy74z6Tc1Z4EQQtRkktxFtWc4G4OPIZkcxQ7vFr1vaR9N/F3RaTVcyMrj4pGtUJRfwVEKIUT1IcldVHvpu34GYAPNaVjb55b2YW+ro5GvCz/p38Lrxx5w/J+KDFEIIaoVSe6ielMU9IeXAHDA4x50Ws0t7yqythtxxnrqi7jfKyI6ISp0lDMhKurvSboOi+otcS/OOWfIVfQYG9x7W7uKCHTjt113McpmGRxeCoW5V48AJsRN0uv1aLVazp07h7e3N3q93jTCmxDlpSgKBQUFnD9/Hq1Wi15/e5NcSXIX1duBxQD8Y2xGk7r+t7WryEA33lAacg5vAgrOw9GV0KRPBQQp7kRarZZ69eqRmJjIuXO3MJa8EGVwdHQkKCgIrfb2GtYluYvqS1Ew7l+MFlhquIv/lnNkuiuF+rlgq9OypKgtT9v8pTbNS3IXt0Gv1xMUFERRUdENx0AX4kZ0Oh02NjYV0gIkyV1UX0n70KaeJFfRs8+xLQFutzcKmJ2NjjA/V/46d5ea3I+sgPwssHOuoIDFnUij0WBra1tps3sJcSukQ52ovvYvBmCtsRmhdfwq5NtsRKAbcUo9Uu0CoSgXjiy/7X0KIUR1I8ldVE+KYrrevszQhmZ13Cpkt5G13QAN6/Wd1AXSa14IYYUsmtw3bNhA7969CQgIQKPRsHjxYrP1iqIwadIk/P39cXBwoHv37hw9evSG+501axZ169bF3t6etm3bsn379kp6B6JS9fyAP3X3ssbYgmbF07berohA9UvCd5kt1QXHVkGeTAUrhLAuFk3u2dnZREVFMWvWrDLXv//++3zyySd8/vnnbNu2DScnJ6Kjo8nLy7vmPn/66ScmTJjAm2++ye7du4mKiiI6OpqUlJTKehuiMmg0XPTvxHPZI8jB3pSUb1cjXxf0Nlp25/lT4BEChgI4tLRC9i2EENWFRZN7z549+b//+z/69et31TpFUfj4449544036NOnD5GRkXz33XecO3fuqhr+5WbMmMHo0aMZMWIETZo04fPPP8fR0ZFvvvmmEt+JqAz7zqg16vreTrg5VExnJVudlib+roCGE77R6sL90jQvhLAu1faa+8mTJ0lKSqJ79+6mZW5ubrRt25YtW7aUuU1BQQG7du0y20ar1dK9e/drblPZMvIK2bwnFnLTLHL8GinlIKx8g8QDmwFodpu3wF0psrgVYJ1NB3XB8X8g51KFHkMIISyp2ib3pKQkAHx9fc2W+/r6mtZd6cKFCxgMhnJtA5Cfn09GRobpkZmZeZvRq3ILDDzxzRb0i0aS/Wl7OLOrQvZr9WJ/hc2fEnr0C6Aykru6v38uekBoL2j/PCgyhKgQwnpU2+RelaZNm4abm5vp0aRJkwrZr95GSwuPPHxIxSnnLMav74PNn4KMRX19dTughPfnh7x2AEQVJ+OKUlJz3382HcPDC6D7m+DkVaHHEEIIS6q2yd3Pzw+A5ORks+XJycmmdVfy8vJCp9OVaxuA1157jfT0dNPjwIEDtxm9SqfV8MrD9/J9s/n8ZWiLVimClW/Ajw9D9sUKOYZVanAPCffM5Lfcluh1Whr7u1bs7r2dcbDVkV1g4OSFrArdtxBCVAfVNrnXq1cPPz8/1qxZY1qWkZHBtm3baNeuXZnb6PV6WrZsabaN0WhkzZo119wGwM7ODldXV9PDxcWlwt6HVqvhv/3aEtPmI/5bOIp8xVYd0/zzjnBqU4Udx9rEnE4DoEmAK3qbiv0z1Wk1NK2tfmHYdyYdigrg8HI4vrZCjyOEEJZi0eSelZVFTEwMMTExgNqJLiYmhoSEBDQaDePHj+f//u//WLJkCbGxsTz++OMEBATQt29f0z66devGzJkzTa8nTJjAl19+ybfffsvBgwd55plnyM7OZsSIEVX87kppNBpef6AJte5+ij4Fb3HMGACZ5+DbB2D9B2CUMakBdeCarbMh5aApuVf09fYSEbXV/e47kw47vlJbUzZ8UCnHEkKIqmbRseV37txJ165dTa8nTJgAwLBhw5g3bx6vvPIK2dnZPPnkk6SlpdGxY0eWL1+OvX3pGOPHjx/nwoULptcPP/ww58+fZ9KkSSQlJdGsWTOWL19+VSe7qqbRaHgpOhQ7Gy0PrvJhqu08Buo2wNr/g1MboP+X4HLtSwd3hJSDsPw/oNNz2OMHAKIqaGS6K5Vcd489mw6dH4TNn4B/lNof4jZnYxJCCEvTKIqiWDqI6ubMmTPUqVOH06dPExgYWOH7/2L9caYtO0R/7Qbetf8WvTEXnLyh3xfQsFuFH6/GWPsOrH8PY0gPwg4Op6DIyNqXulDPy6nCD3X8fBbdPlyPva2WuMnR2GiQpC6EqNbKk5vk08wCnurcgMm9m/C78W565k4lyb4hZJ+H+f3hwB+WDs9yiieKORsQTUGREVd7G+p6OlbKoep5OuFsZ0NeoZFj57MksQshrIp8olnI8A71eKdfBCeoTee0N9jq2RfFqxE0uENr7ikH4cJh0OnZZNMGgKg67hUyE1xZtFd2qgO178OJ9ZB57TERhBCiJpDkbkGPtg3ig4FRFGr0PHJ2EP/1/B8G2+ImaKMRErZaNsCqVFxrp8E97ExSOxg2r6TOdCVKBrOJLUnuPz8O3z0I+36q1OMKIURlk+RuYQNbBvK/R5qj02r4cW8q4xbuodBghK2z4JtoWPWmpUOsGsXTu9Kkr6mnfFQlJ/eI2mqnun1ni5N7g3vUn3G/VepxhRCisklyrwZ6RwUw69EW2Oo0/LUvkTELdlOUdV5d6RFs2eCqQsohOH8ItLZk1L2X4+fVgWUqO7mX9Jg/mJhBQZERmvQBjQ4S98LF45V6bCGEqEyS3KuJHk39+GJoS/Q2WlYeSGb02QfIH7EGWl52f35uquUCrEwltfYG9xB3Qb3dPdDDAS9nu0o9bFAtR1ztbSgoMnIkOVMdgrZ+Z3WlzBQnhKjBJLlXI/eE+fLNsNbY22pZe/g8o1YZyCksHuAmNw2+uBuWPA8FORaNs8KVXG8P78ueKmqSB3XsAdN195Km+fD+6s+4RZV+fCGEqCyS3KuZjiFefDuiDU56HRuPXWD43B1k5Rep05KmnYbd38JX3dSmbGtw/jCcPwhaWwi9n70lI9NV8GQx1xJR3DRv6jHf+AE1lpT91nOOhRB3HEnu1VDb+p58N6otLnY2bD95iaFfbyO9QW94fDE4+UDKAfiyK+yZr7Zh12SmXvJdwcGdvWfSAGgW5F4lh48yjVSnHhcHj9KOddI0L4SooSS5V1Mtgz1YMLotbg627ElI47GvtpHq2x6e2QT1u0BhDvwxBn4eWrNrmJf1kk9MzyU5Ix+dVkN4QMXOBHctEcUtBIcSM8kruQTSdID6M+73mv/lSQhxR5LkXo1FBrrz4+i78HTSE3s2ncFfbuUCbvDYIrhnotqz++Cf8Nld8OsoOH/E0iGXj6LAAx/DXc9CWGmTfCNfFxz1VTPtQYCbPZ5OeoqMCoeSMtWFoT1BZwcXj0JyXJXEIYQQFUmSezXXJMCVhU/ehbeLHYeSMnlkzlZSsgrg7pfgqQ0Q9gCgQNyv8Flb+G00XDhq6bBvjkYDQW2hxzRw8CDmtHrdu7Jmgis7BI3punts8SUB7F0h5F71udzzLoSogSS51wAhvi78/FQ7/N3sOZaSxaAvtnAuLRf8msIjC+Cpf9Ukrxgh9meY1QbWvGXpsMst5rR6q1+zSpoJ7loia1/RqQ6gaUmveWmaF0LUPLeU3E+fPs2ZM2dMr7dv38748eOZM2dOhQUmzNXzcuLnp9oR6OHAqYs5DPpiC6cvFd8S5x9ZnOQ3QOj9apL3DrVswDdy8Tj8OQ5ObgDAYFRMw8BWxW1wl4u48nY4gEY9wNYR0uLh3O4qjUcIIW7XLSX3Rx99lLVr1wKQlJTEvffey/bt23n99deZOnVqhQYoStWp5cjPT7WjrqcjZ1JzGfTFFk5eyC4t4B8Fg39Ua/IlncIAdnwNi5+FSyerPuhrifsdds2DTf8D1ClYswsMOOp1hPi4VGkoJSPVHUnOJLeguFOd3kntC9DtTXCt+Gl/hRCiMt1Sco+Li6NNG3Xmrp9//pmmTZuyefNmFixYwLx58yoyPnGFAHcHfn6qHQ19nElMz2Pg7M3sir9kXsg/ErQ69bmhEDZ8ADEL4Piaqg/4Wup3gRbDoNkQAGIS0gB1vHedtnJmgrsWX1d7fFzsMCpwIPGy2nu3idBpArj4Vmk8Qghxu24puRcWFmJnpw4Nunr1ah588EEAwsLCSExMrLjoRJl8XO1Z+ORdNK3tysXsAgbP2caiPWfKLqyzhYfnQ+Qj0Hxo6fLT2yE1vmoCLkud1vDgJ6Zr2zEl97dXcZN8icgrB7MRQoga7JaSe3h4OJ9//jn//vsvq1atokePHgCcO3cOT0/PCg1QlM3L2Y6fn2pHdLgvBQYjL/y0lw9WHMJoLKPzV2Ar6P8F2BSP1W4ogkVPw6ct1eveaaerNvgymEams1Byj6itHjf2yuSenwX7foFd31bcwfIy4OxuOLfHfLl03BNCVJBbupn4vffeo1+/fnzwwQcMGzaMqKgoAJYsWWJqrheVz1Fvw+whLZm+8jCfrTvOrLXHOXE+mw8HRV3/PvHcS+BeBy4dV69771kALYZCpxfBrQquL2/8GII7qF86NBpyCwyme8yrujNdCVPN/ewVyf3URvj9CXD2heaPqZc78tLVsf5zUyEvTX2eV/y6zOdpcO8UCO+n7jN+E/z4CAS0gCfXlh7r63vVeQO8Q8E7rPhnKNRqADb6yj0BQgirckvJvUuXLly4cIGMjAw8PDxMy5988kkcHR0rLDhxY1qthld6hNHA25nXfo9lWVwSp1Nz+Orx1vi52Ze9kbMPPP4HxG+BddPg5HrY+Y06nG2Lx6HjBHCrXTkBXzwOq99UB+B5+Rg41mL/uXQMRgVvFzv8rxVzJWtafDvc8fNZZOUX4WxX/K/R4B6o3VL9WZSndrT7KALyy9l8n5VS+tzRC1xrg5N36TKjAZJi1WOk7DffVqMDzwbg1ag46Rcnfq8QsHW4hXdbToZCyLmkfrFx8ipdfmqj+h6cfcHeTR23QAhRLdxScs/NzUVRFFNij4+PZ9GiRTRu3Jjo6OgKDVDcnAEtAwnydOSp73cRdzaDPrM28tXjrU0DtJQpuB0MWwKnNqlJ/tS/sOMr2P2dWkv1ClU/0HW24BehJjmAgmw4vhZs7CGke+n+zh+GgizQ2pT90NnCvp/UsvU7g2MtAGIua5LXWChBeLvYEeBmz7n0PPafTadt/eLLSzZ6GP2PeWEHdzDkg727Oha9g3sZz4tflzyvVb90+zqtYcIB831qtPDsVvUcXjhcPKHOIXXUwYJMuHBEfRz66/KNYOA3pffkZyZB+lnwbgR2ZdxxoCiQn6m23ORcKv6ZesXr4p8PfAQeddXtNkyH9e9Cq5HqclBbGOb1Kt23jb36pdHZT+2A6Ox72XM/dZ2Ln/ploKSzpxDVlaKoX2oN+cU/C6AoX/0Mcw0oLRe/Wf1fCG6nfvGH0ktuJdvbOkKb0VX+Fm4puffp04f+/fvz9NNPk5aWRtu2bbG1teXChQvMmDGDZ555pqLjFDehdd1a/DGmA6O+3cGR5Cwe+mIzMwY14/4I/+tvWLcDDP8LTv6rJvn4TWpN/nIdJ5Qm98wk+GkI2LnCa5ddr1/2KpxYy01p0sf0NMbC19tLRAS6cS49j9jLk3tZxu6s+GZyjQZq1VMfoT1KlysKZJy7OuGfP6g2/bsHl5Y99Bf8/SKERMOQn9VlGYnwfT/IuaiWNxbeXDwZiaXJ3bEWoFE/3ErkZ6gtCZnJaitGUR6kJaiP63n8D/VOCYBjq9WJg+p2gqiH1WWGInViJBR1vAZFKe6LcPlr49Wv/SPVL1Og9iE5f0j9IhHQrPTYB/8qbl3QqD812uLnWtBw2fPL1nmHgXNxC0vOJXX0R3tX8Glcut+kOHUbO1d1nd4FtFY8PpjRqH6JL8w1v5PkxDr13Odnqn9nGm0ZD435a69GEHSXun1RARxcopZp0q/0HJ7bo/6dlWxfkjSLih8lideQr+6jKE/9/UQ9UhrvL8PUcv2/VH9HAOvfh9hfrthHQemjLHU7qZ+VJRY+qv5fjdleOrbI4WWw4f3SMi4BNSe57969m48+Ur/B//rrr/j6+rJnzx5+++03Jk2aVKHJvW7dusTHX92r+9lnn2XWrFlXLZ83bx4jRowwW2ZnZ0deXl6FxVSd1anlyG/PtOe5H/ew7vB5nl2wm5fua8SYrg1vXCuu1wnqdlRr8Pt+Ur+RGovUJmPvsNJyOlsIbHN1k7CTN7gFFW9TqP40FBW/LipNLO7BZsm9ZCa4qCqa5vVaIgPdWbE/+cY95qvy+rdGo14icatdOlsdqEkt+4LaHF7CaFBryZcPYGRrr34RuJyNPTjUUpO2g0fxz1rmPy9vaWg1ElqPNk9YLn4wdof6vDAXspLVD+CsJPUSRGaS+jwzWV2XlQzZ59UafYmzu2HP9+p7LEnueWnwRafyn6dhf0K9u9XnR5bD0pfUv7FB35WW+WlI+fc78JvSMSNOrodfhkNQexi5rLTMd30g58JlG2nUlhM7l9KEf+XPsN5qCw6ofTKS94OjJ/hc9n92MxRF/b2X/L/p9KUdZ4vyITNRjcfjsi+BKQfVBGwoUDuM5meqX9byM80fBZc9b/YotH5C3f78IZjdTr289Mrx0v1umK5+dpRHy+Glyb0gC34bpT6f2AdTf+/Nn5Z/GOiwB0qTu0ajzsGBok64VZLcsy+orWE3Q6NTz63uiv99nybqudNelkq9Q9Xjl/wuHGqVL/YKckvJPScnBxcXtdlv5cqV9O/fH61Wy1133VVmIr4dO3bswGAwmF7HxcVx77338tBDD11zG1dXVw4fPmx6bammXktxsbflq8db8c7SQ3yz6STTVx7hWEoW7w6IxN72Bk2iGo36IVnyQVkW9yB4YtXVywd8ef19l9SySr6BAxez8jl9KReAyCoedvZKkabpX2vA7XAaTWmNskTbp9SHsfT/BTs3tbZ8efLWl7NfjM72+uttHdRafklN/1qMBoqryKp6ndXXfhGlyzRa9QvKlTVoTVm17cte2172npy8wL+ZeasGQJ27imv7JTX/K1sB4KoWAbvL/iZtndT36HpFS5hL8ev8jOIan1KcLDOAs2WfC4+6pck9MUb9guDdGMZsLS0zp6uanDVatbZa8kXbeNkXZsVgvt97p0KHcerzpDj46h71/3V8bGmZxc9cfafGjQS3L31ecsmn6IoKU2Br9W/BzkVNbCXnsMxH8TrfpqXba3Xq546iFP9eS85VPbXVsGRbra2aNHV69YuqjV6d6Mn00858vxoN9PpQ/Tu+/HJVm9HQ5MErti1O4Do7tXzJca51KWnE0quXRQxUHxZ2S8m9YcOGLF68mH79+rFixQpeeOEFAFJSUnB1rdipOr29zT/A3n33XRo0aEDnzp2vuY1Go8HPz69C46hpbHRaJvVuQgMfJ978Yz+LY86RcCmHL4a2wtvFzjJBaTTqN+DLlNTaG3g74Wp/gyRSySKKO9WdvJBNem4hbg6WjeeWXf5BpNWWNoNb2pUfkEFt1cflHGvBS4e5LeH9Su9MuNyoFbe330b3qY8rPbOx9HlhXmlNOC+9+GeG+c/8TPCLKt1GowXPEPWSzOUyE4tr3uVgLCp9rrNVv/TYXNFJ1bW22lqgswW9s3krg93lr4uX6Z3VzpuXb/96cmkLQYnub5Yv1ivZu6ktMFfqNlF93I7Wo65e5hVi/r6szC0l90mTJvHoo4/ywgsvcM8999CuXTtArcU3b968QgO8XEFBAfPnz2fChAnXrY1nZWURHByM0WikRYsWvPPOO4SHh1+zfH5+Pvn5pdcTMzMzKzRuSxrSNph6nk48PX8XuxPS6DtrE18Pb0WYX9XMl34jJTPBWeoWuMu5O+oJquVIwqUc4s6m06Gh1403EuJytvbq48pWleupdzc8t/Pq5SNXqJcp4IrOqbrrvL7sC6l/JLxexpeDRxaU6y1dRasFrWXuahE375Z6fQwcOJCEhAR27tzJihWl34a7detmuhZfGRYvXkxaWhrDhw+/ZpnQ0FC++eYb/vjjD+bPn4/RaKR9+/ZmE91cadq0abi5uZkeTZo0qYToLad9Qy8Wj+lAPS8nzqblMuCzzaw5mGzpsADLD15zpQgZqU5UFx7B6nwR/lHgG65ey/VsoDbpuwUW333gpfabsHNRm8R1t1RfE1ZIoyi3NyxWSdIMDKz8wU+io6PR6/X8+WcZTTfXUFhYSOPGjRk8eDBvvVX2NKhX1tzPnj1LkyZNOH36dJW8r6qSllPAswt2s/n4RTQaeP3+xozqWM9ifRIURaH5W6tIyylkydgORFq4Qx3AF+uPM23ZIe6P8OOzIS0tHY4QQpicOXOGOnXq3FRuuqWau9FoZOrUqbi5uREcHExwcDDu7u689dZbGI3GWwr6RuLj41m9ejVPPPFEubaztbWlefPmHDt27Jpl7OzscHV1NT1KOgtaG3dHPd+ObMPgNkEoCvzf3wd57fdYCooq53d2I/EXc0jLKUSv01abywRScxdCWINbSu6vv/46M2fO5N1332XPnj3s2bOHd955h08//ZSJE2+z48M1zJ07Fx8fH3r16nXjwpcxGAzExsbi73+De73vELY6Le/0a8rEB5qg1cDCHad5/JttpGZf477OSlTSma5JgCt6m+pxX3DJSHVnUnO5ZIFzIoQQFeGWPlG//fZbvvrqK5555hkiIyOJjIzk2Wef5csvv6yUKV+NRiNz585l2LBh2NiYX1N6/PHHee2110yvp06dysqVKzlx4gS7d+/mscceIz4+vtw1fmum0WgY1bEeXw9rjbOdDVtPXKLfZ5s4lpJVpXHsKZ7mtbpcbwdwtbelvpc60lSNuCVOCCHKcEvJ/dKlS4SFXT3YQlhYGJcuXSpji9uzevVqEhISGDly5FXrEhISzKaZTU1NZfTo0TRu3Jj777+fjIwMNm/ebHWd5CpC1zAffnumPYEeDpy6mEO/zzax8eiFG29YQfZaeJrXaylpmo8tjk8IIWqaW0ruUVFRzJw586rlM2fOJDIy8raDutJ9992Hoig0atToqnXr1q0zay346KOPiI+PJz8/n6SkJP7+++9KvT2vpgv1c2HxmA60CvYgM6+IYXO38/3Wyp/nvaDIyP5zGUD1uA3uciX3u8t1dyFETXVL9028//779OrVi9WrV5vucd+yZQunT59m6dIyRuwR1ZqXsx0LRrfltd9i+X3PWSYujuN4ShZv9GqMja5yroUfSsqgoMiIm4MtdT2r10yCJb32pVleCFFT3dInd+fOnTly5Aj9+vUjLS2NtLQ0+vfvz/79+/n+++8rOkZRBexsdHw4KIqXo9VxyedtPsW9H21g8Z6zGIy3dbdkmUrub4+y4Exw1xIe4IpGA4npeaRk3hlzEgghrMstj3gQEBDA22+/bbZs7969fP3118yZM+e2AxNVT6PRMKZrQxp4O/PfRbGcvJDN+J9imLX2GOO7N6JnUz+02opJxCUj0zW73pS0FuJkZ0NDb2eOpmQRdzade8JkNC4hRM1SPe4/EtVKj6Z+bHilKy9Hh+LmYMvRlCzG/LCb+z/5lxX7k7jNcY8AiDmdCkCzIPfb3ldlkPvdhRA1mSR3USZnOxvGdG3Iv692ZVy3EFzsbDiUlMlT3+/iwZmbWHso5ZaTfEZeIcfPZwNUi1HpylIy/WysJHchRA0kyV1cl6u9LS/c24h/X+3KmK4NcNTriD2bzoh5O+g/ezMbj14od5IvSZiBHg54OVtohrobMNXcz6ZXSEuFEEJUpXJdc+/fv/9116elpd1OLKIac3fU83J0GCM71OOLDSf4bssp9iSk8djX22hTrxYv3tuItvU9b2pfMdVsspiyNPF3RafVcD4zn+SMfPzc5Lq7EKLmKFfN/fKZ08p6BAcH8/jjj1dWrKIa8HS247/3N2bDy10Z3r4uep2W7Scv8fCcrTz21TZ2xafecB81Ibnb2+po5KvOMbBXBrMRQtQw5aq5z507t7LiEDWMj6s9kx8M56nO9Zn5zzF+3nmajccusPHYBbqEevPivaGmpu3LKYpiSu7VbfCaK0XWduNgYgaxZ9KJDvezdDhCCHHT5Jq7uC3+bg683S+Cf17swsOt6qDTalh3+Dy9Z25k9Hc7OZiYYVY+MT2P85n56LQamgZUv9vgLnf5dXchhKhJJLmLClGnliPvDYxkzYTO9G9eG60GVh1Ipuf//mXMgt0cTc4ESgevCfV1wUGvs2DENxZ52Rjz0qlOCFGT3PIgNkKUpa6XEzMebsazXRvy8eoj/LUvkb9jE1kal0ifqABKUmR1b5IHddx9W52G1JxCzqTmUqdW9RomVwghrkVq7qJSNPRxZuajLVg+vhPR4b4oCiyOOccfMecAaF4DkrudjY4wP1dAxpkXQtQsktxFpQrzc+WLoa3467mOdAvzAcBGq6F1vVoWjuzmyEh1QoiaSJrlRZVoWtuNr4e3Zv+5dAqKjNTzcrJ0SDclsrYbPwCxZ9MsHYoQQtw0Se6iSoVX8x7yV7q85q4oSrWbwU4IIcoizfJCXEcjXxf0Nloy84o4dTHH0uEIIcRNkZq7ENdhq9PSxN+VmNNpdJ2+DludBjsbHXY2WvVhe9lzGx12tpc9t9EWv1af669Rrp6XE5GBbtIqIISoMJLchbiBvs0C2HsmDUWBQoNCoaGIrPyKPUYTf1eGtgumT7MAHPXybymEuD0aRUbnuMqZM2eoU6cOp0+fJjAw0NLhiGogt8BAbqGB/CIDBUVG8ouM5BcayS8yqM+LDMWvL1tmtt5IfqH63LR9kYGcAgO74lPJLzIC4GJvw8CWgTx2VzANvJ0t/K6FENVJeXKTVBGEuAkOel2ljaiXllPALzvPMH9bPPEXc5i76RRzN52iQ0NPht4VTPfGvtjopHuMEOLmVetPjMmTJ6PRaMweYWFh193ml19+ISwsDHt7eyIiIli6dGkVRSvErXF31DP67vqsfbEL345sQ/fGvmg1sOnYRZ6ev5uO763lkzVHScnIs3SoABQajJxLy+VSdgF5hQYZmleIaqja19zDw8NZvXq16bWNzbVD3rx5M4MHD2batGk88MAD/PDDD/Tt25fdu3fTtGnTqghXiFum1Wro3Mibzo28OZOaww/bEvhpx2mSMvKYseoIn6w5SnRTP4beFUzberWqrANeWk4BuxNS2XkqlV3xqew9k0ZeodG0XqMBB1sdjsWtG462NupPvQ4HW53puaO+eHnxstIyNsXr1WWNfF2wlZYKIW5Ltb7mPnnyZBYvXkxMTMxNlX/44YfJzs7mr7/+Mi276667aNasGZ9//vlNH1euuYvqIr/IwPK4JL7bEs+u+FTT8ka+zgy9K5i+zWvjYm9bYcdTFIUTF7LZFZ/KrlOp7EpI5VhK1lXldFoNBmPlfHTU93Lip6fa4e1iVyn7F6Kmsqpr7kePHiUgIAB7e3vatWvHtGnTCAoKKrPsli1bmDBhgtmy6OhoFi9efN1j5Ofnk59f2v05MzPztuMWoiLY2ejo06w2fZrVZv+5dOZvTWDxnrMcSc5i4h/7eXfZIfq1qM3Qu+oS6udS7v3nFRrYdyZdTebxl9gVn0pqTuFV5ep7O9EyyINWdT1oGexBfS9njIpCbqGB3AK1Y2BuYfHPAgM5BUVlrCsip8BAXnE587JGcguKOJ+Zz4kL2YyYt52FT7bD2a7af0QJUS1V6/+ctm3bMm/ePEJDQ0lMTGTKlCl06tSJuLg4XFyu/iBLSkrC19fXbJmvry9JSUnXPc60adOYMmVKhcYuREULD3BjWv8IXrs/jN92neH7rfGcOJ/N/K0JzN+aQJu6tRjaLpjocD/0NmU3a6dk5qk18vhUdsansv9cOoUG8xq43kZLVKAbLYNr0SrYgxbBHtRy0l+1Ly0aXHTaCm05OHUhmwGzNxN3NoNnF+zm62GtpIleiFtQrZvlr5SWlkZwcDAzZsxg1KhRV63X6/V8++23DB482LTss88+Y8qUKSQnJ19zv1fW3M+ePUuTJk2kWV5Ua4qisOX4Rb7fGs/KA8mmZnIvZzsGt6nDw63rkJlXVFwrT2Vn/CVOX8q9aj9ezna0ClZr5S2CPWga4HbNLwdVIeZ0GoPnbCW30MCAFoFMfyhSBvgRAitrlr+cu7s7jRo14tixY2Wu9/PzuyqJJycn4+fnd9392tnZYWdXen0vIyPj9oMVopJpNBraN/SifUMvktLz+GF7Aj9uT+B8Zj6f/nOMT/+5+v9Eo4FQXxdaFifzlkG1qFPLoVolz2Z13Jk1pDmjv9vFb7vP4O9mz0vRoZYOS4gapUYl96ysLI4fP87QoUPLXN+uXTvWrFnD+PHjTctWrVpFu3btqihCISzDz82eCfc24rl7GrJyfzLfbz3F1hOXcNLraB6k1shbBXvQLMgd1wpsRq8s94T58k6/prz6Wywz1x7D182eoXcFWzosIWqMap3cX3rpJXr37k1wcDDnzp3jzTffRKfTmZrdH3/8cWrXrs20adMAGDduHJ07d+bDDz+kV69eLFy4kJ07dzJnzhxLvg0hqoytTkuvSH96RfqTnlOIk52uxg6A83DrIJLS8/lo9RHe/CMOHxc7osOv3wonhFBV6//6M2fOMHjwYEJDQxk0aBCenp5s3boVb29vABISEkhMTDSVb9++PT/88ANz5swhKiqKX3/9lcWLF8s97uKO5OZoW2MTe4nnuzVkcJs6GBV4/sc97Iq/ZOmQhKgRalSHuqoi97kLUX0UGYw89f0u1hxKwd3Rll+fbk9DHxl3X9x5ypObavbXeiGE1bPRafn00eY0q+NOWk4hw77ZTnI1GYpXiOpKkrsQotpz1Nvw9bBW1PNy4mxaLsPn7iAz7+rBdoQQKknuQogawdPZjm9HtMHL2Y6DiRk8PX8XBUXGG28oxB1IkrsQosYI8nRk3ojWOOl1bDp2kVd+3Yuxksa4F6Imk+QuhKhRmtZ2Y/ZjLbHRalgcc473VhyydEhCVDuS3IUQNc7djbx5b0AkAF+sP8HcTSctEkdeoYH5W+N5b/kh1h5KITu/yCJxCHGlaj2IjRBCXMuAloEkZeTxwYrDTP3rAL6u9twf4V8lx87MK2T+1gS+3niCC1kFAMzmOLY6Dc2DPOjY0IsODb2ICnSr8WMNiJpJkrsQosZ6tksDktLz+H5rPON/isHTSU/b+p6VdrxL2QXM23SSeZtPkZGn1tIDPRy4q74n205e5PSlXLafvMT2k5eYseoILnY23NXAk44NvegY4kV9L6dqNY6/sF6S3IUQNZZGo2Hyg+EkZ+Sx8kAyo7/bya/PtKeRb/nntr+e5Iw8vtxwgh+2J5BTYACgoY8zz3ZpQO+oANO0tAkXc9h47AIbj51n07GLpOcWsupAMqsOqBNa+bvZ06GhF51CvGjfwAtvF7trHlOI2yEj1JVBRqgTombJKzQw5Ktt7IpPxd/Nnt+fbY+/m8Nt7zfhYg6fbzjOrzvPUGBQb7trWtuVMV0aEh3uh1Z77Vq4wahw4FwG/x47z6ZjF9hxKvWqW/fC/FzUJvwQL9rWq4WjXupb4trKk5skuZdBkrsQNU9aTgEDZm/m+PlsQn1d+Pnpdrg53NoMeEeTM/ls3XGW7D2HofhWu9Z1PRjTtSGdG3nfUtN6XqGBHacusfHYBTYdu0DcWfOppW11GloUX6/vGOJFRG25Xi/MSXK/TZLchaiZzqTm0P+zzaRk5tO2Xi2+G9UGOxvdTW8feyadWWuPsXx/kmlZ50bejOnakDb1alVorJeyC9h8XE30/x69wJnUXLP1LvY2tKvvSeu6tQiv7UrT2m41YrpeUXkkud8mSe5C1FwHzmUw6IstZOUX0SvSn08faX7d5nOAbScuMmvdcTYcOW9a1iPcjzFdGxIR6FbZIaMoCgmXiq/XH73A5uPq9for1fV0pGltNyKKH+G13W65dULUPJLcb5MkdyFqtk3HLjB87nYKDQqjOtZj4gNNriqjKArrjpzns7XH2HEqFQCdVkOfqACe6dKAkArulFceBqPC/nPpbDp2kX1n0og9m35Vzb5E8GUJv2mA+tPNURK+NSpPbpLeG0IIq9OhoRfTH4pi3MIYvt54En83e57oVB8Ao1Fh+f4kZq09xv5z6nVvvU7LQ60CeeruBgR5OloydED9khEZ6E5koLtpWWp2AXHn0ok9m07cWfXn6Uu5xF/MIf5iDn/vSzSVrVPLQU32l9Xy3R31FngnwlIkuQshrFKfZrVJzsjjnaWH+L+/D1LLSY+iwGfrjnH8fDYADrY6hrQNYvTd9fF1tbdwxNfn4aSnU4g3nUK8TcvScgqIO5thlvATLuVw+lIupy/lsjS2tO9AoEdpwm9a243I2m54OEnCt1bSLF8GaZYXwjooisLUvw4wd9Mps+Wu9jYMb1+X4R3qUcvKElx6TiH7i2v4JUn/1MWcq8ppNHBfE1+e6FSfVsEeMrhODSDN8kIIgTrIzcReTUjJyOfv2ES8nPWM6lifx+4KwsVKe567OdrSvqEX7Rt6mZal56oJX63dZxB3Np2TF7JZsT+ZFfuTiQp044lO9enZ1E9uv7MSUnMvg9TchbAuBqPCnoRUwgPccNDf/K1x1uxYSiZfbzzJb7vPmgbXqe3uwIgOdRnUuo7cdlcNSW/52yTJXQhxp7iQlc/8rfF8vyWei9nqJDjOdjY80roOwzvUJdDD8h0MhUqS+22S5C6EuNPkFRpYvOcsX208ybGULEDttd+jqR+jO9WnWR13ywYoypWbqvXFlWnTptG6dWtcXFzw8fGhb9++HD58+LrbzJs3D41GY/awt6/evWCFEMLS7G11PNImiJXj72buiNZ0bOiFwajw975E+s7axMDZm1kel2gajldUb9W6Q9369esZM2YMrVu3pqioiP/+97/cd999HDhwACcnp2tu5+rqavYlQHqBCiHEzdFqNXQN9aFrqA8HEzP46t+TLNl7lp3xqeyMTyWoliMjO9TloVZ1cLKr1inkjlajmuXPnz+Pj48P69ev5+677y6zzLx58xg/fjxpaWm3fBxplhdCiFIpGXl8tyWe+dviSctRh8V1tbfh0bbBDGsfXCEz8Ikbs5pm+Sulp6cDUKvW9SdwyMrKIjg4mDp16tCnTx/2799fFeEJIYRV8nG156XoUDb/5x7e6tuUel5OZOQV8fn643R6by0v/BRD3Nl0S4cpLlNjau5Go5EHH3yQtLQ0Nm7ceM1yW7Zs4ejRo0RGRpKens706dPZsGED+/fvv+Y3nfz8fPLz802vz549S5MmTaTmLoQQZTAaFdYcSuGrf0+w7eQl0/K76tdidKf6dA31ueFkPaL8rLK3/DPPPMOyZcvYuHFjuRJuYWEhjRs3ZvDgwbz11ltllpk8eTJTpky5arkkdyGEuL59Z9L4euNJ/tpX2tmuoY8z47uHcH9Tf0nyFcjqkvvYsWP5448/2LBhA/Xq1Sv39g899BA2Njb8+OOPZa6XmrsQQtyec2m5fLv5FD9sTyAzrwiAMD8XJtzbiHub+ErH5gpgNdfcFUVh7NixLFq0iH/++eeWErvBYCA2NhZ/f/9rlrGzs8PV1dX0cHGx3FSPQghREwW4O/Da/Y3Z/J97eKF7I1zsbDiUlMmT3++iz6xNrD2cQg2oS1qNap3cx4wZw/z58/nhhx9wcXEhKSmJpKQkcnNL5zV+/PHHee2110yvp06dysqVKzlx4gS7d+/mscceIz4+nieeeMISb0EIIe4oLva2jOsewr+vdmVM1wY46nXsO5POiLk7GPj5FjYfu2DpEO8I1Tq5z549m/T0dLp06YK/v7/p8dNPP5nKJCQkkJhYOo9xamoqo0ePpnHjxtx///1kZGSwefNmmjRpYom3IIQQdyR3Rz0vR4fx7ytdGd2pHnY2WnbFp/LoV9t4ZM4Wdpy6dOOdiFtWI665VzW5z10IISpWSkYes9Ye48ftpykwqBPV3N3ImxfvbUSUDG17U6zmmrsQQgjr4ONqz5Q+TVn7chcGtwnCRqthw5Hz9Jm1iSe+3cmBcxmWDtGqSHIXQghRZWq7OzCtfwT/vNiFAS0C0Wpg9cFk7v/kX55dsIujyZmWDtEqSHIXQghR5YI8HflwUBSrJnSmd1QAGg0sjU3ivo83MH7hHk5eyLZ0iDWaJHchhBAW08DbmU8HN2f5uLvpEe6HosDimHN0n7GeV37dy+lLOZYOsUaSKX2EEEJYXKifC58PbUnc2XRmrDrCP4dS+HnnGRbtOcugVnUYe0/DCpmgxmhUyCsykFtgILfQQF6hgbxCI7Y6LSE+zlYzop4kdyGEENVG09pufDO8NbsTUpmx8ggbj11gwbYEftl1hkfbBBHq50JugYG8IgN5xQk6t9BAboGxjGUG8ouMpkSeW2igoMh4zWN7Oeu5O8SbzqHe3B3ijYeTvgrfecWSW+HKILfCCSFE9bDtxEU+XHmE7ZVwX7ydjRZ7Wx0Otjoy8grJKTCY1mk0EBXoTpdQb7qE+hBR2w2dhWv1Vje2fFWT5C6EENWHoihsPHaBH7cnUFCk4KDX4WCrxcFWh33xQ12mw962NGE76HWm5yVl7G20xT91Zk3wBUVGdsZfYv3h86w/cp5DSea99ms56ekU4kWX4lq9p7NdVZ8GSe63S5K7EELc2RLTc1l/+DzrDp9n07ELZOYXmdZpNBBZ243OjbzpHOpDszruVVKrl+R+myS5CyGEKFFoMLI7PpV1R9RkfzDRfMAdd0dbOoV4q8m+kTfeLpVTq5fkfpskuQshhLiW5Iw81h85z/rD5/n36Hky8orM1jet7UqXRj50DvWmeR13bHQVc9e5JPfbJMldCCHEzSgyGIk5nca6w+dZdySFuLPmtXpXexs6hXgzbUAErva2t3Ws8uQmuRVOCCGEuEU2Oi2t6taiVd1avBQdyvnMfDYcOc+6I2qtPi2nkB2nLuFiV7XpVpK7EEIIUUG8XewY0DKQAS0DMRgV9p5J43xmPhpN1d5GJ8ldCCGEqAQ6rYYWQR4WObaMLS+EEEJYGUnuQgghhJWR5C6EEEJYGUnuQgghhJWR5C6EEEJYGektXwajUZ0SMDEx0cKRCCGEEKqSnFSSo65HknsZkpOTAWjTpo2FIxFCCCHMJScnExQUdN0yMvxsGYqKitizZw++vr5otbd35SIzM5MmTZpw4MABXFxcKihC6ybnrPzknJWfnLPyk3NWfhV5zoxGI8nJyTRv3hwbm+vXzSW5V7KMjAzc3NxIT0/H1dXV0uHUCHLOyk/OWfnJOSs/OWflZ6lzJh3qhBBCCCsjyV0IIYSwMpLcK5mdnR1vvvkmdnZ2lg6lxpBzVn5yzspPzln5yTkrP0udM7nmLoQQQlgZqbkLIYQQVkaSuxBCCGFlJLkLIYQQVkaSeyWbNWsWdevWxd7enrZt27J9+3ZLh1RtTZs2jdatW+Pi4oKPjw99+/bl8OHDlg6rxnj33XfRaDSMHz/e0qFUe2fPnuWxxx7D09MTBwcHIiIi2Llzp6XDqrYMBgMTJ06kXr16ODg40KBBA9566y2ky1apDRs20Lt3bwICAtBoNCxevNhsvaIoTJo0CX9/fxwcHOjevTtHjx6ttHgkuVein376iQkTJvDmm2+ye/duoqKiiI6OJiUlxdKhVUvr169nzJgxbN26lVWrVlFYWMh9991Hdna2pUOr9nbs2MEXX3xBZGSkpUOp9lJTU+nQoQO2trYsW7aMAwcO8OGHH+Lh4WHp0Kqt9957j9mzZzNz5kwOHjzIe++9x/vvv8+nn35q6dCqjezsbKKiopg1a1aZ699//30++eQTPv/8c7Zt24aTkxPR0dHk5eVVTkCKqDRt2rRRxowZY3ptMBiUgIAAZdq0aRaMquZISUlRAGX9+vWWDqVay8zMVEJCQpRVq1YpnTt3VsaNG2fpkKq1V199VenYsaOlw6hRevXqpYwcOdJsWf/+/ZUhQ4ZYKKLqDVAWLVpkem00GhU/Pz/lgw8+MC1LS0tT7OzslB9//LFSYpCaeyUpKChg165ddO/e3bRMq9XSvXt3tmzZYsHIao709HQAatWqZeFIqrcxY8bQq1cvs781cW1LliyhVatWPPTQQ/j4+NC8eXO+/PJLS4dVrbVv3541a9Zw5MgRAPbu3cvGjRvp2bOnhSOrGU6ePElSUpLZ/6ibmxtt27attHwgs8JVkgsXLmAwGPD19TVb7uvry6FDhywUVc1hNBoZP348HTp0oGnTppYOp9pauHAhu3fvZseOHZYOpcY4ceIEs2fPZsKECfz3v/9lx44dPP/88+j1eoYNG2bp8Kql//znP2RkZBAWFoZOp8NgMPD2228zZMgQS4dWIyQlJQGUmQ9K1lU0Se6iWhozZgxxcXFs3LjR0qFUW6dPn2bcuHGsWrUKe3t7S4dTYxiNRlq1asU777wDQPPmzYmLi+Pzzz+X5H4NP//8MwsWLOCHH34gPDycmJgYxo8fT0BAgJyzakqa5SuJl5cXOp3ONDd8ieTkZPz8/CwUVc0wduxY/vrrL9auXUtgYKClw6m2du3aRUpKCi1atMDGxgYbGxvWr1/PJ598go2NDQaDwdIhVkv+/v40adLEbFnjxo1JSEiwUETV38svv8x//vMfHnnkESIiIhg6dCgvvPAC06ZNs3RoNULJZ35V5gNJ7pVEr9fTsmVL1qxZY1pmNBpZs2YN7dq1s2Bk1ZeiKIwdO5ZFixbxzz//UK9ePUuHVK1169aN2NhYYmJiTI9WrVoxZMgQYmJi0Ol0lg6xWurQocNVt1geOXKE4OBgC0VU/eXk5KDVmqcLnU6H0Wi0UEQ1S7169fDz8zPLBxkZGWzbtq3S8oE0y1eiCRMmMGzYMFq1akWbNm34+OOPyc7OZsSIEZYOrVoaM2YMP/zwA3/88QcuLi6ma1Fubm44ODhYOLrqx8XF5ar+CE5OTnh6eko/het44YUXaN++Pe+88w6DBg1i+/btzJkzhzlz5lg6tGqrd+/evP322wQFBREeHs6ePXuYMWMGI0eOtHRo1UZWVhbHjh0zvT558iQxMTHUqlWLoKAgxo8fz//93/8REhJCvXr1mDhxIgEBAfTt27dyAqqUPvjC5NNPP1WCgoIUvV6vtGnTRtm6daulQ6q2gDIfc+fOtXRoNYbcCndz/vzzT6Vp06aKnZ2dEhYWpsyZM8fSIVVrGRkZyrhx45SgoCDF3t5eqV+/vvL6668r+fn5lg6t2li7dm2Zn1/Dhg1TFEW9HW7ixImKr6+vYmdnp3Tr1k05fPhwpcUjs8IJIYQQVkauuQshhBBWRpK7EEIIYWUkuQshhBBWRpK7EEIIYWUkuQshhBBWRpK7EEIIYWUkuQshhBBWRpK7EEIIYWUkuQshqgWNRsPixYstHYYQVkGSuxCC4cOHo9Fornr06NHD0qEJIW6BTBwjhACgR48ezJ0712yZnZ2dhaIRQtwOqbkLIQA1kfv5+Zk9PDw8ALXJfPbs2fTs2RMHBwfq16/Pr7/+arZ9bGws99xzDw4ODnh6evLkk0+SlZVlVuabb74hPDwcOzs7/P39GTt2rNn6Cxcu0K9fPxwdHQkJCWHJkiWmdampqQwZMgRvb28cHBwICQm56suIEEIlyV0IcVMmTpzIgAED2Lt3L0OGDOGRRx7h4MGDAGRnZxMdHY2Hhwc7duzgl19+YfXq1WbJe/bs2YwZM4Ynn3yS2NhYlixZQsOGDc2OMWXKFAYNGsS+ffu4//77GTJkCJcuXTId/8CBAyxbtoyDBw8ye/ZsvLy8qu4ECFGTVNp8c0KIGmPYsGGKTqdTnJyczB5vv/22oijqdLxPP/202TZt27ZVnnnmGUVRFGXOnDmKh4eHkpWVZVr/999/K1qtVklKSlIURVECAgKU119//ZoxAMobb7xhep2VlaUAyrJlyxRFUZTevXsrI0aMqJg3LISVk2vuQggAunbtyuzZs82W1apVy/S8Xbt2ZuvatWtHTEwMAAcPHiQqKgonJyfT+g4dOmA0Gjl8+DAajYZz587RrVu368YQGRlpeu7k5ISrqyspKSkAPPPMMwwYMIDdu3dz33330bdvX9q3b39L71UIayfJXQgBqMn0ymbyiuLg4HBT5Wxtbc1eazQajEYjAD179iQ+Pp6lS5eyatUqunXrxpgxY5g+fXqFxytETSfX3IUQN2Xr1q1XvW7cuDEAjRs3Zu/evWRnZ5vWb9q0Ca1WS2hoKC4uLtStW5c1a9bcVgze3t4MGzaM+fPn8/HHHzNnzpzb2p8Q1kpq7kIIAPLz80lKSjJbZmNjY+q09ssvv9CqVSs6duzIggUL2L59O19//TUAQ4YM4c0332TYsGFMnjyZ8+fP89xzzzF06FB8fX0BmDx5Mk8//TQ+Pj707NmTzMxMNm3axHPPPXdT8U2aNImWLVsSHh5Ofn4+f/31l+nLhRDCnCR3IQQAy5cvx9/f32xZaGgohw4dAtSe7AsXLuTZZ5/F39+fH3/8kSZNmgDg6OjIihUrGDduHK1bt8bR0ZEBAwYwY8YM076GDRtGXl4eH330ES+99BJeXl4MHDjwpuPT6/W89tprnDp1CgcHBzp16sTChQsr4J0LYX00iqIolg5CCFG9aTQaFi1aRN++fS0dihDiJsg1dyGEEMLKSHIXQgghrIxccxdC3JBcvROiZpGauxBCCGFlJLkLIYQQVkaSuxBCCGFlJLkLIYQQVkaSuxBCCGFlJLkLIYQQVkaSuxBCCGFlJLkLIYQQVkaSuxBCCGFl/h/3oxYE5rDpCgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax2 = ax1.twiny() #A\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0) #B\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbbea6d-8ac3-4a0b-8130-081eeee871a4",
   "metadata": {},
   "source": [
    "#根据上面的折线图我们可以看出这个模型过拟合了，原因是因为神经网络中有1.6亿个参数，但是训练集数据多样性过小，而且训练轮次过多，导致模型过于关注特征之间的细节，所以导致过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940a37a-672b-44c7-9e95-d1017b7a63bd",
   "metadata": {},
   "source": [
    "#上面我们已经完成了对模型的训练过程，接下来我们要讨论文本生成策略，也就是采样策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5dd73166-37a3-4d5c-a43c-03abc39361d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know after.\n",
      "\n",
      "\n",
      "\n",
      "\"Oh, and his cheeks paled a little under their handsome sunburn's welcome was\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "410f0915-508e-4054-82a2-48402706f9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'closer', 1: 'every', 2: 'effort', 3: 'forward', 4: 'inches', 5: 'moves', 6: 'pizza', 7: 'toward', 8: 'you'}\n"
     ]
    }
   ],
   "source": [
    "# temperature scaling\n",
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "print(inverse_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "283ae2d1-5164-4298-8430-32e339f105ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
      "        1.0120e-04, 3.5758e-01, 4.0122e-03])\n",
      "3\n",
      "forward\n"
     ]
    }
   ],
   "source": [
    "#假设这是‘every effort moves you’的 logits\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "print(probas)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(next_token_id)\n",
    "print(inverse_vocab[next_token_id])\n",
    "#.item() 是将单一的张量元素转换为一个python的原生数值。例如int或float数据类型\n",
    "#这是上面的那种方法选取最高概率作为下一个词的预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a33e8b34-1649-44f3-bdbb-599bc0c674a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac3555b-95ab-4206-b8a8-7ca012d1351e",
   "metadata": {},
   "source": [
    "#multinamial函数是pytorch中用于从给定的概率分布中进行抽样的函数\n",
    "torch.multinomial(input, num_samples, replacement=False, *, out=None) → LongTensor\n",
    "返回是抽样样本的索引\n",
    "此外input函数可以归一化处理过或者不进行处理也行，该函数会自动帮助进行归一化\n",
    "#bicount函数是 PyTorch 中用于统计整数张量中每个值的出现次数的函数。该函数返回一个 1D 张量，表示 input 张量中每个整数值的频率或加权和。输出张量的索引代表 input 中出现的整数值，其值代表该整数值在 input 中出现的次数或加权统计结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2c963a39-5339-41b2-94a6-e477d5429f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 0, 1, 1, 1, 1, 0, 0, 0, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "input = torch.tensor([0, 4, 5, 0, 10, 10, 2, 3])\n",
    "\n",
    "# 统计每个整数的出现次数\n",
    "result = torch.bincount(input)\n",
    "\n",
    "print(result)\n",
    "#索引值代表的就是整数的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "85b9f1e9-cea1-4d9c-9c4d-baafbfd0c194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a2ab3-27ed-4852-9040-114f58c86518",
   "metadata": {},
   "source": [
    "#我们可以看出概率高的单词自然就被抽样的次数就多，这种抽样的好处就在于不会固定的预测一个单词，其他低频的单词也会被抽到。增加了生成文本的随机性和多样性，降低模型对于高频模式的的依赖，使得模型处理新的场景时具有一定的泛化能力，使得语言的回答更具有一定的创造力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b41e9d-d34d-489a-a8d4-4685d76d6de9",
   "metadata": {},
   "source": [
    "# temperature scaling说白了就是将输出的logits张量除以一个大于0的数（temperature）,进一步控制分布和选择过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "18213d4e-92f6-4d86-86e4-cee05c1e2ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
      "        1.0120e-04, 3.5758e-01, 4.0122e-03]), tensor([1.8530e-10, 3.5189e-26, 2.6890e-38, 9.9099e-01, 5.7569e-23, 4.4220e-37,\n",
      "        2.9718e-38, 9.0133e-03, 2.8514e-22]), tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898])]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "#Temperatures greater than 1 result in more uniformly distributed token probabilities, and Temperatures smaller than 1 will result in more confident (sharper or more peaky) distributions. Let's illustrate this by plotting the original probabilities alongside probabilities scaled with different temperature values:\n",
    "temperatures = [1, 0.1, 5]             #A\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "print(scaled_probas)\n",
    "x = torch.arange(len(vocab))\n",
    "print(x)\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
    "                   bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4fcd8-ed19-42a8-9050-55e1fea2ab88",
   "metadata": {},
   "source": [
    "#当 temperature 设置为非常小的值（如 0.1）时，生成的分布会更加尖锐，因此multinomial函数几乎总是选择最可能的 token（这里是 ‘forward’），其行为接近 argmax 函数。相反，当 temperature 设置为 5 时，生成的分布更接近均匀分布，其他 token 被选中的频率更高。这种情况下，生成的文本多样性增加，但也更可能出现无意义的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3498877e-e9a5-4f12-8bbe-36f1bc7631fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the temperature is 1\n",
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n",
      "the temperature is 0.1\n",
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "992 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "8 x toward\n",
      "the temperature is 5\n",
      "153 x closer\n",
      "68 x every\n",
      "55 x effort\n",
      "223 x forward\n",
      "102 x inches\n",
      "50 x moves\n",
      "43 x pizza\n",
      "218 x toward\n",
      "88 x you\n"
     ]
    }
   ],
   "source": [
    "for i ,probas in enumerate(scaled_probas):\n",
    "    print(f\"the temperature is {temperatures[i]}\")\n",
    "    print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17086c6-cbc3-4788-8a63-194e38e5f5ce",
   "metadata": {},
   "source": [
    "#我们可以发现再增加tmperature后，明显句子的生成的多样性和创造性增强，但是也会生成例如\"every effort moves you pizza\"这种比较离谱的单词，所以我们不需要概率较小的单词进行生成，而是主要随机取样前几个概率较高的单词就行了。所以我们在此引入top-k采样，例如我们将前k个概率值进行保留，然后将其他概率进行mask成-inf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207e2cbb-9d5c-4fe5-8ef3-9f410bc1b888",
   "metadata": {},
   "source": [
    "#.topk函数函数是 PyTorch 中用于获取张量中前 k 个最大（或最小）值及其索引的函数。返回值如下：\n",
    "values, indices = torch.topk(tensor, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8da7fd45-ee78-47da-8f64-e357d12ed20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "603cc35b-013a-4780-b9f3-cc17cdd66379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n",
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],   #A\n",
    "    input=torch.tensor(float('-inf')),              #B\n",
    "    other=next_token_logits                         #C\n",
    ")\n",
    "print(new_logits)\n",
    "\n",
    "#A 识别出小于 top 3 最小值的 logits\n",
    "#B 将这些较小的 logits 赋值为负无穷大\n",
    "#C 保留所有其他 token 的原始 logits\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "214a6331-baa0-433f-b590-ad14e90b3f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 5.4 A modified text generation function with more diversity\n",
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=1.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):                             #A\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:                                   #B\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "\n",
    "        if temperature > 0.0:                                       #C\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:                                                       #D\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:                                      #E\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "\n",
    "\n",
    "#A For循环与之前相同：获取logits，仅关注最后的时间步\n",
    "#B 在新步骤中，通过top-k采样过滤logits\n",
    "#C 在新步骤中应用temperature scaling\n",
    "#D 在未使用temperature scaling时，执行贪婪的下一个token选择\n",
    "#E 如果遇到序列结束token且指定了eos_id，则提前停止生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b4dbbd78-3689-44e4-b866-8dacac57e174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you how I, in talking amate skill, he painted can to see it\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f55a2-1998-45da-927b-3cc8e0f4496f",
   "metadata": {},
   "source": [
    "根据你的观察，你能想到哪些应用场景适合较低的 temperature 和 top-k 设置吗？反之，哪些应用场景适合较高的 temperature 和 top-k 设置？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99d07f-b8a9-4973-bdf9-9888ed4d2663",
   "metadata": {},
   "source": [
    "低 temperature 和低 top-k：适合生成确定性输出，应用于对准确性、连贯性要求高的任务。\n",
    "高 temperature 和高 top-k：适合生成多样化的、富有创造性的内容，应用于需要探索或创新的场景。\n",
    "中等设置：适合平衡输出，适用于聊天机器人、自动内容生成等需要既连贯又具有一定变化的场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538f216-8409-4705-96d3-fe09653c2f0a",
   "metadata": {},
   "source": [
    "generate 函数有哪些不同的设置组合可以强制生成确定性行为，即禁用随机采样，使其输出始终一致，类似于 generate_simple 函数？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e78d5c5f-f5c0-4bb7-a38d-738974a03ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know after.\n",
      "\n",
      "\n",
      "\n",
      "\"Oh, and his cheeks paled\n",
      "Output text:\n",
      " Every effort moves you know after.\n",
      "\n",
      "\n",
      "\n",
      "\"Oh, and his cheeks paled\n"
     ]
    }
   ],
   "source": [
    "token_ids2 = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=None,\n",
    "    temperature=0\n",
    ")\n",
    "token_ids3 = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=None,\n",
    "    temperature=0\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids2, tokenizer))\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids3, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "123bfc02-825c-406b-b5ed-b817b902e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存模型\n",
    "#torch.save(model.state_dict(), \"model.pth\")\n",
    "#保存优化器梯度下降历史\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde9b15-c861-490d-a05c-c56d27afa377",
   "metadata": {},
   "source": [
    "#如果保存完model后，下一次仅仅使用模型推理不要进一步训练和优化那么就只用保存model和load model就行，但是如果还想在以后的实验过程中继续训练模型那么我们需要将优化器一起进行save，因为保存优化器会保存使用历史数据动态调整每个模型参数的学习率。没有这些信息时，优化器会重置，模型可能无法有效学习，甚至无法正确收敛，进而失去生成连贯文本的能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1823b-c8f1-4d74-b16e-13d5a8e309f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载模型,一般进行推理的时候我们并不希望丢弃某些神经元所以在这里我们使用.eval\n",
    "# model = GPTModel(GPT_CONFIG_124M)\n",
    "# model.load_state_dict(torch.load(\"model.pth\"))\n",
    "# model.eval()\n",
    "\n",
    "#加载模型和优化器\n",
    "# checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "# model = GPTModel(GPT_CONFIG_124M)\n",
    "# model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "# optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dffbfacc-6f6e-46e8-ab33-d3ea51e21cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#尝试从openAI中加载预训练权重\n",
    "!pip install tensorflow>=2.15.0 tqdm>=4.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "77262e36-228c-42b5-80fb-c414dfc47e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x22ca8832bd0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "072698f2-bf60-4563-9410-e28e438e31da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████████████████████████████████████████████████████████████████████| 77.0/77.0 [00:00<?, ?iB/s]\n",
      "encoder.json: 100%|██████████████████████████████████████████████████████████████| 1.04M/1.04M [00:00<00:00, 1.23MiB/s]\n",
      "hparams.json: 100%|████████████████████████████████████████████████████████████████| 90.0/90.0 [00:00<00:00, 9.77kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████████████████████████████████████████| 498M/498M [02:10<00:00, 3.82MiB/s]\n",
      "model.ckpt.index: 100%|██████████████████████████████████████████████████████████| 5.21k/5.21k [00:00<00:00, 2.73MiB/s]\n",
      "model.ckpt.meta: 100%|██████████████████████████████████████████████████████████████| 471k/471k [00:00<00:00, 853kiB/s]\n",
      "vocab.bpe: 100%|████████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 636kiB/s]\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "89c0c183-29b5-464a-b961-a89ad38bef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "25db603e-013a-4669-96d5-746c119c43eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#我们尝试将GPT2中的配置设置为我们设计的GPTModel\n",
    "# First, we create a dictionary that lists the differences between the different GPT model sizes, as explained in Figure 5.17:\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "# Suppose we are interested in loading the smallest model, \"gpt2-small (124M)\". We can use the corresponding settings from the model_configs table able to update our full-length GPT_CONFIG_124M we defined and used earlier throughout the chapter as follows:\n",
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "#OpenAI 在多头注意力模块的线性层中使用了偏置向量，以实现查询（query）、键（key）和值（value）矩阵的计算。偏置向量在现代 LLM 中已不再常用，因为它们对提升模型性能没有帮助，因而不再必要。\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})\n",
    "# We can now use the updated NEW_CONFIG dictionary to initialize a new GPTModel instance:\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a516c58e-a946-44e1-8c1c-84965bf5291e",
   "metadata": {},
   "source": [
    "为此，我们首先来定义一个简单的assign工具函数，用于检查两个张量或数组（左侧和右侧）的维度或形状是否一致，并将右侧张量作为可训练的 PyTorch 参数返回："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "af6f17f3-3b0d-4c77-865c-c9014807f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dbe74d8d-828c-4ee0-a414-f5fb5bfb44ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将params字典中的权重加载到我们的模型当中\n",
    "# Listing 5.5 Loading OpenAI weights into our GPT model code\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])               #A\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    for b in range(len(params[\"blocks\"])):                                       #B\n",
    "        q_w, k_w, v_w = np.split(                                                #C\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])                   #D\n",
    "\n",
    "\n",
    "#A 将模型的位置嵌入和token 嵌入的权重设置为 params 中指定的值\n",
    "#B 遍历模型中的每个 Transformer 模块\n",
    "#C 使用 np.split 函数将注意力和偏置权重分为三等份，分别用于查询、键和值组件\n",
    "#D OpenAI 的原始 GPT-2 模型在输出层中复用了 token 嵌入的权重，以减少参数总量，这一概念称为权重共享"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ee5d4fd4-d018-4465-990c-b38b764c66a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward an equal share for each vote plus half. Inequality is often not an accurate representation of human worth; to know the\n"
     ]
    }
   ],
   "source": [
    "#其实我们可以用下面简单的方法将parameter加载到我们的模型中,上面那种只是开发过程去检测是否有维度不匹配的情况\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)\n",
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd668d-9d06-41ea-9511-fd9328db112f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
